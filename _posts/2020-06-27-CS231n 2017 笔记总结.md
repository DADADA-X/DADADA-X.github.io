---
layout:     post
title:      "CS231n 2017 笔记总结"
date:       2020-06-27 10:00:00
author:     "DadaX"
tags:
    - 深度学习
---

[CS231n Lecture](/Users/dadada/Desktop/DadaX/Selflearning/CS231n lecture/Lecture)

# introduction

* 计算机视觉的历史1960s to 2017
* 计算机视觉问题包括：image classification, objection localization, object detection and scene understanding
* [Imagenet](http://www.image-net.org/) 最大的图像分类数据集。从2012年开始，CNN总是winning



# image classification

* **图像分类的challenges**：视角变化 viewpoint variation、光照条件 illumination conditions、deformation、occlusion遮挡、background clutter背景干扰、类内差异（Intra-class variation

  <img src="https://i.loli.net/2020/06/28/lg3yOBDF5YHnJkG.png" alt="image-20191027174302759" style="zoom:50%;" />
  
* 深度学习 - **data-driven approach**

* **NN & KNN**

  * Nearest Neighborhood：最接近的样本
  * KNN - K nearest neighborhood：majority vote from K closest points

* **Distance Metric 距离度量**
  
  * L1距离：$d_1(I_1, I_2) = \sum_p|I_1^p-I_2^p|$，适用于特征向量对任务有重要意义
* L2距离：$d_2(I_1, I_2) = \sqrt{\sum_p(I_1^p-I_2^p)^2}$，适用于input指示一个通用向量，不知道实际意义。
  
* 超参数 **hyperparameters** - 提前指定的。problem-dependent

* **数据拆分** - 用来选择超参：

  1. all data
  
  <img src="https://i.loli.net/2020/06/28/cvfZJYs1q4rXzmo.png" alt="image-20191027172505880" style="zoom:50%;" />
  
  2. train & test
  
  ![image-20191027172544451](https://i.loli.net/2020/06/28/4kCqydhX9LeQYJW.png)
  
  3. train, val & test
  
  ![image-20191027172757724.png](https://i.loli.net/2020/06/28/F9GynQVMC5jtlxa.png)
  
  4. 交叉验证 cross - validation（用于小数据集，dl不常用，太耗时）
  
  ![image-20191027172843204.png](https://i.loli.net/2020/06/28/yeIUJmXjWfhsrnE.png)

![image-20191027172954259.png](https://i.loli.net/2020/06/28/nCyQZ9foURq8TMj.png)

* cnn关注图像，rnn关注语言。

* **linear classification** 线性分类，就是在高维空间用线性分类面来划分一个类别
	$$
	s=f(x,W) = Wx+b
	$$

	* *W*的每一行对应一个分类模版（可以可视化），算x与每一类的点乘（会乘一个cos），相似的output比较大
	  
	* *x*要strech成column -> pytorch, fc前x.view(batch_size, feature_num)

  * *b*不与数据相乘，只代表一些独立数据偏好值，比如数据集猫比狗多，猫的b就比狗大。
  
* **image features**

  (输入线性分类，before神经网络)
  
  * color histogram颜色梯度
  * histogram of oriented gradients(HoG) 方向梯度直方图
  * bag of words（visual words）词袋
  
  but **Image feature** vs **ConvNets**
  
  <img src="https://i.loli.net/2020/06/28/xRGgTerLSVbdOKv.png" alt="image-20191028103839377" style="zoom:50%;" />

# Loss Functions

* **loss function**：现在的classifier表现好不好。<u>总的loss是每个数据的loss的平均</u>

$$
L = \dfrac{1}{N}\sum_iL_i(f(x_i, W), y_i)
$$

* 多类**SVM**损失/**Hinge loss**

  当正确分类的score高于错误分类的score某个safety margin时，loss=0
  
  $$L_i = \sum_{j \ne y_i}max(0, s_j - s_{y_i}+1) \in [0, +\infty)$$  
  <img src="https://i.loli.net/2020/06/28/EmMiFgryIQKC4Yb.png" alt="image-20191027204610602" style="zoom:50%;" /><img src="https://i.loli.net/2020/06/28/e8d9OKwJs3VQfxb.png" alt="image-20191027205153232" style="zoom:50%;" /> <img src="https://i.loli.net/2020/06/28/EbFyipOuGDvV8WP.png" alt="image-20191027205227412" style="zoom:50%;" />

  最后的$L=\dfrac{1}{N}\sum_{i=1}^NL_i$求平均（所以pytorch里一般都是求平均）

* **logistic regression loss**/pytoch中的BCELoss/二元的交叉熵损失
  $$
  h_\theta(x)=\dfrac{1}{1+e^{-y}}\text{（sigmoid）}=p(y=1|x, \theta) \\
  L = -y\log(h_\theta(x))-(1-y)\log(1-h_\theta(x))
  $$
  
* softmax classifier/**softmax loss**/多项logistic regression/交叉熵损失

  <img src="https://i.loli.net/2020/06/28/XsObB7rKJotkS42.png" alt="image-20191027211823140" style="zoom:50%;" />
  $$
  L_i = -\log(\dfrac{e^{s_{y_i}}}{\sum_je^{s_j}}) \in[0, +\infty)
  $$

* 为了防止过拟合：**正则化** - 目的：减轻模型复杂度

  > 奥卡姆剃刀：among competing hypotheses, the simplest is the best

  $$
  L(W) = \dfrac{1}{N}\sum^N_{i=1}L_i(f(x_i, W), y_i)+ \lambda R(W)
  $$

  * L2正则：$R(W) = \sum_k\sum_lW_{k, l}^2$，权值衰减，考虑w元素的整体分布
  * L1正则：$R(W) = \sum_k\sum_l|W_{k, l}|$，prefer稀疏解，倾向于让w大部分元素接近0
  * 弹性网络正则(L1+L2)：$R(W) = \sum_k\sum_l\beta W_{k, l}^2+|W_{k, l}|$
  * max norm regularization
  * **Dropout**
  * 高级：**Batch normalization**

# Optimization-Gradient descent

* 梯度计算

  * 数值梯度法 numerical gradient - **用于debug，验证解析梯度是否正确**

  $$
  \dfrac{df(x)}{dx} = \lim_{h\to 0}\dfrac{f(x+h)-f(x)}{h}
  $$

  $W+h, \Delta lose/h$

  <img src="https://i.loli.net/2020/06/28/DbkcBzsWQjGm29F.png" alt="image-20191028100926773.png" style="zoom:50%;" />

	* 解析梯度 analytic gradient
	
	  算出梯度表达式，然后直接算*dW*
	
	  ![image-20191028101330656.png](https://i.loli.net/2020/06/28/cIl2VMRdvwuTY9i.png)
	
	在实际操作时常常将分析梯度法的结果和数值梯度法的结果作比较，以此来检查其实现的正确性，这个步骤叫做**梯度检查**。

* 梯度下降：

  随机初始化，计算loss（总误差是整个训练集误差的均值），计算梯度，更新权重（梯度反方向），直到收敛，从而获得更低的损失值。

  * 随机梯度下降SGD：每次取一个data（pytorch中就是mini-batch）
    
  * Mini-batch SGD: 每次迭代取一个mini-batch【**通常为$2^n(32/64/128)$ ，便于gpu加速**】，算 loss和梯度，更新各个参数。
  $$
  L(W) = \dfrac{1}{N}\sum^N_{i=1}L_i(x_i, y_i, W)+ \lambda R(W)\\
  
    \nabla_WL(W) = \dfrac{1}{N}\sum^N_{i=1}\nabla_WL_i(x_i, y_i, W)+ \lambda \nabla_WR(W)
  $$


#Backpropagation 

* computational graphs 计算图，可以聚合起来，只要我们可以写出它的local gradient

  <img src="https://i.loli.net/2020/06/28/slZwrPqGObLIBAo.png" alt="image-20191028104733403" style="zoom:50%;" />

* **Backpropagation 反向传播**：

  * 递归调用**链式法则**来计算计算图中每个变量的梯度【梯度指明了整个表达式对于该变量的敏感程度】

  <img src="https://i.loli.net/2020/06/28/BvktJVWQIUGplsf.png" alt="image-20191028104916428" style="zoom:50%;" />

  * 每个节点的梯度 = 上游返回的梯度*local gradient

    local gradient：

    * 加法门：1
    * max门：1或0
    * 乘法门：另一个变量的值
    * sigmoid门：x(1-x)

  * gradients for **vectorized code** - jocobian matrix

    <img src="https://i.loli.net/2020/06/28/1z3H564ENLJdCMB.png" alt="image-20191028110229055" style="zoom:50%;" />

    * 乘法门这里：$dW$就是$q*x^T$

    * always check: 变量的梯度与该变量形状相同

# Neural Networks

<img src="https://i.loli.net/2020/06/28/C3MqIgtTwcBKQdL.png" alt="image-20191028110828897" style="zoom:50%;" />

* 2-layer Neural Network（N层不算输入层）
  $$
  f = W_2\max(0, W_1x)
  $$
  <img src="https://i.loli.net/2020/06/28/BzjKpiqdRrgH5Ns.png" alt="image-20191028111035357" style="zoom:50%;" />

  3-layer Neural Network
  $$
  f = W_3\max(W_2\max(0, W_1x))
  $$
  <img src="https://i.loli.net/2020/06/28/xpVYyAjhPZI62Xo.png" alt="image-20191028111059409" style="zoom:50%;" />

* 激活函数 activation functions

  <img src="https://i.loli.net/2020/06/28/RZSOzEx7Hya9otp.png" alt="image-20191028111006743" style="zoom:50%;" />

  * **sigmoid**
    $$
    \sigma(x)=1/(1+e^{-x})
    $$

    * 压缩到[0, 1]
    * 曾经很常用

    问题：

    1. 饱和的神经元会杀死梯度，从而无法得到梯度流的反馈
    2. 不是zero-centered，更新参数时，会沿着全正/全负去迭代，非常低效（zig zag path）
    3. exp() 计算昂贵

  * **tanh**

    * 压缩到[-1, 1]
    * Zero centered
    * 饱和的神经元会杀死梯度

  * **ReLU: **f(x) = max(0, x)

    * 正方向不会饱和
    * 计算效率很高
    * 收敛块（比sigmoid和tanh）
    * biologically plausible

    问题：

    * 不是zero-centered
    * x<0时，梯度为0，神经元失活【所以初始化relu神经元时，加一点很小的正偏差】

  * **Leaky ReLU**: f(x) = max(0.01x, x)

    * 不会饱和
    * 计算效率很高
    * 收敛块（比sigmoid和tanh）
    * 不会失活

  * **PReLU**(parametric rectifier)：$f(x) = max(\alpha x, x)$

    * $\alpha$可学习

  * **Maxout**：$\max(w_1^Tx+b_1, w_2^Tx+b_2)$

    * ReLU + Leaky ReLU
    * 两个线性函数的最大，不会饱和，不会失活
    * 参数变多

  > In practice
  >
  > * 用relu，注意lr
  > * 尝试leaky relu/maxout/elu(在图里)
  > * 尝试tanh（don't expect much）
  > * 不要用sigmoid

* 数据预处理

  * zero-centered data

    ```python
    X -= np.mean(X, axis=0)
    ```

  * normalized data 归一化

    ```python
    X /= np.std(X, axis=0)
    ```

  * PCA - 展示数据的相关性结构

  * Whitening - 使之符合高斯分布

  > In practive
  >
  > * center only
  > * 训练阶段会决定均值，test时，用相同的经验均值来0中心化
  >   * alexnet对所有图像的每个像元取均值 mean image = [32, 32, 3] array
  >   * vggnet是所有图像对每个channel的均值 mean image = 3 numbers
  > * 别的都不常用

* 权重初始化(use Xavier init)

  1. 小随机数初始化（tanh）：一个神经网络的层中的权重值很小，那么在反向传播的时候就会计算出非常小的梯度（因为梯度与权重值是成比例的）。这就会很大程度上减小反向传播中的“梯度信号”，okay for 小网络，但在深度网络中，就会出现问题。

  2. 加大权重（tanh） - 梯度爆炸

  3. Xavier initialization（tanh）：

     `W = np.random.randn(fan_in, fan_out)/np.sqrt(fan_in)`

     * 如果数据少，会除以一个较小的数，得到较大的权重

     * 如果数据多，除以一个较大的数，得到较小的权重
     * 以便得到相同的输出方差，使其在输出中得到相同的传播

  4. 但是如果用（ReLU），会杀死一半的神经元，方差减半，得不到正确的方差，就会向0靠近，最后就会失活——

     `W = np.random.randn(fan_in, fan_out)/np.sqrt(fan_in/2)`

     Additional/2，得到和未使用relu相比的等效输入输出

* 缓解**过拟合**

  <img src="https://i.loli.net/2020/06/28/IaSHAftqPOiLRgo.png" alt="image-20191028180242561" style="zoom:40%;" />
  
  * 在loss上+regularization term：L2, L1, Elastic net（L1+L2）
  
  * **Batch Normalization** 批量归一化 (use)
  
    * 防止过拟合，fancier regulurization，可以slightly减少dropout
  
    * 用在FC/Conv之后，非线性之前
  
    * improve gradient flow
  
    * 可以有更高的学习率
  
    * 减少对initialization的依赖
  
    * 在test时，用training的均值方差和其他param（$\gamma,\beta$）
  
    * step：
  
      1. 计算经验均值$E[x^{(k)}]$和方差$Var[x^{(k)}]$for each dimension
  
      2. normalize
      $$
       \hat x^{(k)} = \dfrac{x^{(k)}-E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}
      $$
  
      3. 恢复恒等映射
      $$
       y^{(k)} = \gamma^{(k)}\hat x^{(k)}+\beta^{(k)}
      $$
       	$\gamma,\beta$是可学习的
  
  * **model ensemble**
  
    1. 在不同的随机初始值上训练几个不同的独立的模型
    2. 测试时，取他们的平均值
  
    ——得到2%的extra performance，减少泛化误差。
  
    * 可以集成训练过程中的快照
  
  * **Dropout**，一般在全连接层，前向传播过程中，随机的将一些神经元置零（卷积层就是随机把整个激活映射置0），rate：commonly 0.5
  
    * 避免特征之间相互适应，这样不会过度依赖特征组合，而是通过不同的零散特征来判断。
    * 测试时：消除dropout的随机性 - 乘上dropout probability（p）
  
  * 数据增强 data augmentation
  
    在随机迭代过程中，以某种方式随机地转换图像，使标签保留不变，然后用随机转换地图像进行训练
  
    * filp
    * crop
    * scale
    * 色彩抖动
    * translation
    * rotation
    * stretching
    * shearing
    * lens distortion
    * ……
  
* fancier optimization【7】

  * **SGD**

    problem：

    * 两个特征scale不一样，会zig zag
    * local minima&鞍部，会get stuck
    * 因为是随机的，所以can be noisy

  * **SGD+Momentum**
    $$
    v_{t+1}=\rho v_t + \nabla f(x_t)\\
    x_{t+1}=x_t-\alpha v_{t+1}
    $$

    * 保持一 个不随时间变化的速度，把梯度加到这个速度上，$\rho$相当于摩擦，通常为0.9/0.99；

    * 再在这个速度的方向上步进，这样可以减少我们在敏感方向上步进的数俩个，增加不敏感方向的速度。（会越过极小值点）

    <img src="https://i.loli.net/2020/06/28/7xaSCBfH4Jcr25s.png" alt="image-20191028165821352" style="zoom:50%;" />

  * Nesterov Momentum
    $$
    v_{t+1}=\rho v_t -\alpha \nabla f(x_t+\rho v_t)\\
    x_{t+1}=x_t+v_{t+1}
    $$
    令$\tilde{x}_t=x_t+\rho v_t$
    $$
    \begin{aligned} 
    v_{t+1}& =\rho v_t -\alpha \nabla f(\tilde{x}_t)\\
    x_{t+1}& =x_t-\rho v_t+(1+\rho)v_{t+1}\\
    			 & =x_t+v_{t+1}+\rho(v_{t+1}-v_t)
    \end{aligned}
    $$
    

    * 在速度方向步进，再向梯度方向步进（有校正因子，不会那么剧烈的越过局部极小值点）

    <img src="https://i.loli.net/2020/06/28/zRJc8HYsMOXPmvB.png" alt="image-20191028170216265" style="zoom:50%;" />

  * AdaGrad

    ```python
    grad_squared += dx * dx
    x -= learning_rate * dx / (np.sqrt(grad_squared)+1e-7)
    ```

    * i see. dx是单独的，比如有x1, x2两个参数，梯度各是各的，所以 ->
  * 除以梯度平方累计，加速在小梯度维度的学习速度
  
* RMSProp
  
    ```python
    grad_squared = decay_rate * grad_squared + (1 - decay_rate) * dx * dx
  ```
  
    * decay_rate一般为0.9/0.99
  * 让梯度平方按照一定比例下降 - 给梯度平方加动量
  
* **Adam**（almost）
  
  * momentum+adagrad/rmsprop
  
    ```python
    first_moment = beta1 * first_momnet + (1 - beta1) * dx	# 动量
    second_moment = beta2 * second_moment + (1 - beta2) * dx * dx
    
    first_unbias = first_moment / (1 - beta1 ** t)	# 偏置校正
    second_unbias = second_moment / (1 - beta2 ** t)
    
    x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + 1e-7)	# adagrad/rmsprop
    ```
  ```
  
    * Commonly:
      * Beta1 = 0.9
      * Beta2 = 0.999
    * Lr = 1e-3 or 5e-4
  
  ```
***

  <center>以上都是一阶优化</center>
* 二阶优化
    * 用梯度和hessian矩阵来得到二阶近似
    * step to 这个近似
    * 优：有时候不用lr
    * 缺：dl不实用，计算costly
    * **L-BFGS** 如果可以affod，try this

# Convolutional Nerural Networks

* neural networks history

  * 1957，perceptron machine 感知机，Frank Rosenblatt，无backpropogation，用于识别字母表
  * 1960，多层感知机，Adaline/Madaline，无backpropogation
  * 1986，backpropogation，Rumeelhart，
  * 梯度消失和svm阻碍了nn的发展
  * 2006，解决梯度消失：**无监督预训练对<u>权值进行初始化</u>（Restricted Boltzmann machines）+有监督训练微调**，Hinton，开启了深度学习在学术界和工业界的浪潮。
  * 2012，AlexNet, Hinton, wins the imagenet
  * After that NN is widely used in various applications.

* Convolutional neural networks history:

  * 1959 to 1968 ，Hubel & Wisel，发现了hierarchical organization
  * 1997，**LeNet**，Yann Lecun，document recognition，CNN的开端。
  * 2012，**AlexNet**，Hinton，加入relu，Dropout，Data augmentation，多gpu计算。
  * 从2012年开始，cnn开始用于各种任务
    * Image classification.分类
    * Image retrieval.检索
      - Extracting features using a NN and then do a similarity matching. 提取特征，相似度匹配
    * Object detection. 检测，边界框，精确定位
    * Segmentation. 分割，标记轮廓像素
      - Each pixel in an image takes a label.
    * Face recognition. 
    * Pose recognition 
    * Medical images 医学影像解释和诊断
    * Playing Atari games ，用 reinforcement learning玩游戏
    * Galaxies classification.星系分类
    * Street signs recognition.路标识别
    * Image captioning.

* Convolutional Neural Networks

  * 全连接层，通常在卷积神经网络中的最后一层，用于把所有信息聚合到一起

    <img src="https://i.loli.net/2020/06/28/cbmhCxH1zIygO8F.png" alt="image-20191028113226055" style="zoom:50%;" />

    **a number：**是W与整个input data相乘的结果

  * convolution layer 卷积层

    <img src="https://i.loli.net/2020/06/28/g2eXlbUMSZwLiYu.png" alt="image-20191028113422750" style="zoom:50%;" />

    * 每个神经元只与输入数据的一个局部区域连接。
    * 该连接的空间大小叫做神经元的感受野（receptive field）。
    * 卷积核在图像空间上滑动，权重相同。
    * 可以有好几个卷积核，维度相同，作用域图像的相同区域，有几个卷积核，activation maps的深度就是几(一个卷积核对应一个activation map)。

    **a number: **是w和图像一个小区域相乘的结果$w^Tx+b$

    * K：通常为2的n次幂

    * stride（**必须整除**）：==$output\_size = (N-F)/stride+1$==

    * zero pad：$output\_size = (N+2*P-F)/stride+1$

      通常为$F//2$，之后$output\_size = input\_size$

    * 参数个数：$(F*F*D+1)*n$

      <img src="https://i.loli.net/2020/06/28/1YmNXtbz3GjTgph.png" alt="image-20191028114622151" style="zoom:50%;" />

  * pooling layer - 为了有更少的参数。

    * 只做平面，不做深度；pytorch里面默认跳跃窗口，stride=F

    * max pooling：commonly，代表卷积核在图像任意区域的受激程度。

    <img src="https://i.loli.net/2020/06/28/2CumbOFvEJxcrAR.png" alt="image-20191028115029925" style="zoom:50%;" />

# train neural network

* **babysitting learning process**
1. 数据预处理
	
2. 选择合适的nn结构
3. 初始化网络，forward pass，double check loss是否合理。比如10类，softmax loss，loss应该差不多-log(1/10)左右，check；加上regularization，loss变大（**sanity check 完整性检查**）。
4. 开始训练：
	* 从一个很小的数据集开始（比如20个sample），regularization = 0，这样可以拟合非常好（overfit），看是否能把训练损失降为0（0.002597 is okay）
	* 用上所有数据， 加上一个很小的正则化项，确定最优 lr（important，首先要调的参数），先设一个1e-6，loss不动，lr太小，再设一个1e-3，loss inf，lr太大，所以lr在[1e-3...1e-5]之间


* **hyperparameter optimization**

  * 交叉验证策略（一次可以搜索2/3/4个超参）：

    1. 只训练几个epochs，得到大概多少(范围要足够大)
    2. 跑更长时间，更精确的搜索（uniform均匀采样，最好用log空间）

    * 如果cost>3*original cost就爆炸了，早点停下来

    * random search（better） vs grid search - random sample hyperparams

    <img src="https://i.loli.net/2020/06/28/GkUVpq3JyCSPDOs.png" alt="image-20191028162142891" style="zoom:50%;" />

  * 需要优化的超参
    * 网络结构
    * 学习率，衰减和更新
    * 正则化

  * 结果分析

    * learning rate

      <img src="https://i.loli.net/2020/06/28/xDvi9KEIOWCz3pj.png" alt="image-20191028162455540" style="zoom:50%;" />

    * initialization

    <img src="https://i.loli.net/2020/06/28/KLXZPG6dsOvI5Hl.png" alt="image-20191028162531102" style="zoom:50%;" />

    * regularization

    <img src="https://i.loli.net/2020/06/28/25wgCU3b86Emxu7.png" alt="image-20191028162603704" style="zoom:50%;" />

  * **learning rate decay**，在sgd+momentum比较重要，adam不常用

    lr太大了最后会降不下去，但是大一点比较快，所以可以这样learning rate decay。

    <img src="https://i.loli.net/2020/06/28/QDZWOIAJ3UNgpfy.png" alt="image-20191028172252022" style="zoom:50%;" />

    * exponential decay:

      $\alpha = \alpha_0e^{-kt}$

    * 1/t decay:

      $\alpha = \alpha_0/(1+kt)$

    * 不要一开始就用，尝试一下到底需不需要。

* **transfer learning**

  1. train on imagenet
  2. finetuning

  * 如果数据非常小，就只修改最后一层fc。重新初始化，冻结前面的层，只训练最后这层，使其收敛

  * 如果有更多的数据，就可以更新网络的更大一部分。

    因为泛化能力已经很强了，指示想做一些微调来适应数据，所以lr低一点，原来的1/10

  |                         | Very similar dataset                                   | Very different dataset |
  | ----------------------- | ------------------------------------------------------ | ---------------------- |
  | **very little data**    | 在imagenet与训练模型的基础上，只训练最后一层线性分类器 | try不同的线性层        |
  | **quite a lot of data** | 精调一些些的层                                         | 精调很多层             |

  * pretrain 预训练 非常普遍。
    1. 找一个很大的相似dataset，训练一个很大的卷积神经网络
    2. transfer learn to your dataset

# Deep learning software

* CPU vs GPU

  * GPU 显卡（NVIDIA is better）more cores, slower ->  parallel tasks
  * CPU: less cores, faster -> sequential tasks

  * GPU框架：
    * CUDA (NVIDIA only)
    * OpenCI

* **Deep learning Frameworks**

  * focus on: Tensorflow (Google), PyTorch (Facebook)
  * Numpy doesn't run on GPU.

[mbadry1/CS231n-2017-Summary](https://github.com/mbadry1/CS231n-2017-Summary)

# Recurrent Neural Networks

* RNN序列

  <img src="https://i.loli.net/2020/06/28/4FR7P8zYOCHhVjs.png" alt="image-20191030103800353" style="zoom:50%;" />

  * O2o，Vanilla Neural Networks，前馈神经网络；也有用在rnn的：
    * “[Multiple Object Recognition with Visual Attention](https://arxiv.org/abs/1412.7755)”, ICLR 2015.
    * generating a [captcha](http://ieeexplore.ieee.org/document/7966808/)
  * o2m，image captioning，图像->a seq of 文字
  * m2o，Sentiment Classification，文字->情感
  * m2m，Machine Translation，文字->文字；Video classification on frame level

* RNN works on a **sequence of related data**.

  <img src="https://i.loli.net/2020/06/28/PX8jIYGFmBKaUTL.png" alt="image-20191030105018904" style="zoom:50%;" />

  h：hidden state
  $$
  h_t = W_{hx}x_t + W_{hh}h_{t-1}\\
  y_t = W_{hy}h_t
  $$
  每一个step用的是相同的W

* 计算图

  <img src="https://i.loli.net/2020/06/28/E6GunSlzigPMBNj.png" alt="image-20191030105304248" style="zoom:50%;" />

  然后再从出来一个或者多个y

* **example：**character-level language model语言模型，就是在预测下一个字母是什么

  **train**

  <img src="https://i.loli.net/2020/06/28/BaOu8eSdA5tDqz2.png" alt="image-20191030113408414" style="zoom:50%;" />

  **test**

	<img src="https://i.loli.net/2020/06/28/cu93a2OEHipYBP6.png" alt="image-20191030113511719" style="zoom:50%;" />
	
	前一步的结果+hidden state=下一步的输入
	
* 反向传播
	
	* **Truncated Backpropagation through time**，沿时间截断反向传播，使训练过程中在更少的先前时间步上进行更新，可以缓解梯度爆炸问题。
	
	* 只在chunks上反向传播，而不是整个sequence
	
	* hidden state前向传播，但只在很少的steps中后向传播
	
	  *Carry hidden states forward in time forever, but only backpropagate for some smaller number of steps*
	
	<img src="https://i.loli.net/2020/06/28/zIZ8P2CbNJTYRm6.png" alt="image-20191030151103365" style="zoom:50%;" />