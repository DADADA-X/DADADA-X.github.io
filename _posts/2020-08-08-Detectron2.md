---
layout:     post
title:      "Detectron2 代码笔记"
date:       2020-08-08 10:00:00
author:     "DadaX"
tags:
    - 深度学习
---

# Detectron2 代码结构

<img src="https://i.loli.net/2020/06/28/YqP3D9GfbBWyJSu.png" alt="image-20200615162825673.png" style="zoom:40%;" />

<center>代码结构
</center>

![image-20200617093312363](https://i.loli.net/2020/06/17/gOd3FeDmScKMk9W.png)

<center>调用关系
</center>
**核心部分**

- `configs`：实例**yaml配置文件**合集。

- `datasets`：**数据集准备**工作，主要是readme.md➡介绍各个数据集的基本结构，以及需要如何预处理。|| 存放数据集的地方（需要自己放）

- `tools`：常用脚本，如训练、benchmark、可视化等，比较重要的是`train_net.py`和`plain_train_net.py`，可仿照。

- `detectron2`：项目主要代码都在这里了，重要的文件有：

  - `config`：超参数配置，有两个重要文件

    - `config.py`：定义了`CfgNode`类，继承于`fvcore`库的`CfgNode`，又继承于`yacs`库的`CfgNode`；还提供了`get_cfg()`方法，会返回一个含有默认配置的`CfgNode`。
  - `default.py`：默认配置文件。
    
  - 🌟`engine`。

    - `launch.py`：代码启动器，可以根据命令决定是否采用分布式训练（或者单机多卡）或者单机单卡训练。
    - `train_loop.py`提供了三个重要的类：**1)** `HookBase`：Hook的基类，用于指定训练前后或每个step前后需要做什么事，有`before_train`, `after_train`, `before_step`, `after_step ` 四个函数；**2)** `TrainerBase`：Trainer的基类，有三种函数：①`register_hooks`将用户定义的一些hooks进行注册，就是把hook上到一个list里，之后遍历这个list就行了 ②`train`函数：执行③中的步骤； ③ 对于如何遍历hook list，有1)中提到的四种方式，`before_train`, `after_train`, `before_step`, `after_step`；还有一个就是`run_step`，就是平常我们在编写训练过程的代码，例如读数据，训练模型，获取损失值，求导数，反向梯度更新等，这里没定义；**3)** `SimpleTrainer`：继承`TrainerBase`，定义了`run_step`，后面可以继承这个类做进一步的自定义。

    * `hooks.py`：定义了很多继承自`HookBase`的Hook

    - `defaults.py`提供了两个类：`DefaultPredictor`和`DefaultTrainer`，其中`DefaultTrainer`就继承自`SimpleTrainer`，里面包含了很多可以可以自定义的函数，如`build_model, build_optimizer, build_lr_scheduler`等；两个函数`default_argument_parser`和`default_setup`

    > 总而言之，engine提供训练/预测/评估相关的主要代码，最重要的是提供了`DefaultPredictor`和`DefaultTrainer`，以及用hook构建trainer的方式：
    >
    > * `HookBase`➡`hooks.py`里各种类，如读数据，训练模型，获取损失值，求导数，反向梯度更新等
    >
    > * `TrainerBase`➡`SimpleTrainer`➡`DefaultTrainer`➡自定义的trainer
    >

  - `layers`：用于构建modeling的基本单元 ➡ 🌟`modeling`：自定义模型

  - 🌟`data`：定义dataloader，可参考`build.py\build_detection_train_loader(cfg)`

    - **`datasets`**：主要负责定义各个数据集的具体的加载分析方法
    - sampler 负责dataloader 生成batch 数据时对dataset 的抽样方法
    - transforms 就负责记录所有的数据增强操作
    - **`build.py`**： 负责 build_detection_data_loader ,
    - catalog.py 中定义了 DatasetCatalog 和 MetaCatalog ， 后者用于对每个数据集记录元信息，如每个类别idx对应什么具体类别等
    - common.py 定义了MapDataset ， 即上文一直在说的MyDataset
    - dataset_mapper 中定义了MapFunc 类， 用于进行数据的增强和标签的处理

  - `solver`：定义了optimizer和lr_scheduler || `utils`：工具，包括Registry

**Tutorial部分**

- `demo`：里面有一个用于预测的`demo.py`，预测和可视化都封装在`predictor.py`
- `docs`：是detectron2的官方documentation
- `projects`：基于Detectron2的项目，DensePose/PointRend/TensorMask/TridentNet
- 在知乎里，Detectron2的开发人员介绍，如果想要利用detectron2直接复现所有论文可能比较困难（我的理解就是直接修改detectron2中的代码），一种比较好的方式就是将detectron2作为一个包来调用来构建新的模型。
  - 这里的三个项目就是利用detectron2复现模型的示例。【**之后自己的代码结构看参考这个结构写**】
- `tests`：提供了一些测试代码
  - `train_net.py`/`plain_train_net.py`：**【自己写train时可参考】**

# 官方Tutorials

## Install

- [x] 安装，没什么问题

官网有两种安装方式

```
python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'
# (add --user if you don't have permission)

# Or, to install it from a local clone:
git clone https://github.com/facebookresearch/detectron2.git
python -m pip install -e detectron2
```

方法2库在clone下来的地方，不会放进`./miniconda/env/detectron2/lib/python3.8/site-package`里，因此如果改变了位置，就要重新执行`python -m pip install -e detectron2`

>python -m mode : run library module as a script(terminates option list) 运行模块库as a脚本
>
>pip -e                     : install a project in editable mode(i.e. setuptools "develop mode") from a local project path or a VCS url 安装project从local project或者url

参考`solaris`的方法，进入clone的仓库，再执行`pip install .`则会在`site-package`里生成`detectron2`，clone的仓库detectron2就可以随便动了>.<

## Get Started With Detectron2

- [x] **官方demo**

会把参数解析`def get_parser():`和配置设置`def setup_cfg(args):`封装乘函数

>  To run **on cpu**, add `MODEL.DEVICE cpu` after `--opts`. Like: `python demo.py --opts MODEL.DEVICE cpu`

```python
def setup_cfg(args):
    # load config from file and command-line arguments
    cfg = get_cfg()
    cfg.merge_from_file(args.config_file)
    cfg.merge_from_list(args.opts)
    # Set score_threshold for builtin models
    cfg.MODEL.RETINANET.SCORE_THRESH_TEST = args.confidence_threshold
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = args.confidence_threshold
    cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = args.confidence_threshold    
		cfg.freeze()	# 让配置不能再被修改，强行修改会报AttributeError说CfgNode is immutable
    return cfg
```

另外detectron API还封装了cv2读图像的函数

```python
from detectron2.data.detection_utils import read_image
```

把预测和可视化都封装进了`predictor.py`，直接实例化一个demo，调用函数run_on_image就行了

- [x] **train_net & plain_train_net**

* train_net

首先需要准备训练用的数据集。following [datasets/README.md](https://github.com/facebookresearch/detectron2/blob/master/datasets/README.md)

首先，`def setup(args)`，定义超参数配置函数：

```python
def setup(args):
    """
    Create configs and perform basic setups.
    """
    cfg = get_cfg()	# 获取已经配置好默认参数的cfg
    cfg.merge_from_file(args.config_file)	# 将yaml文件中指定的超参数对默认值进行覆盖
    cfg.merge_from_list(args.opts)	# 通过命令行中opts参数中的指定超参数组成的list对默认值进行覆盖
    cfg.freeze()	# 冻结超参数，避免程序不小心修改
    default_setup(cfg, args)	# engine/default.py中提从的默认配置函数
    return cfg
```

还定义了`Trainer`类，继承自`DefaultTrainer`，会自动解析cfg，之后值需要调用`trainer.train()`就可以开始训练了

```python
'''main函数'''

def main(args):
    cfg = setup(args)

    if args.eval_only:
        ...
    trainer = Trainer(cfg)
    trainer.resume_or_load(resume=args.resume)
    if cfg.TEST.AUG.ENABLED:
        trainer.register_hooks(
            [hooks.EvalHook(0, lambda: trainer.test_with_TTA(cfg, trainer.model))]
        )
    return trainer.train()
```

* plain_train_net

没有调用那么多default类别，用torch自己写的。(自由创建自己的优化器,并编写训练逻辑：使用PyTorch通常很容易,并且使研究人员可以看到整个训练逻辑更清晰并具有完全控制权，支持研究过程中可能想要的一些非标准行为)

* 他们都可以在命令行直接训练，通常需要输入config文件，也可以测试，参数是` --eval-only`

## Setup Builtin Datasets

各种内置dataset的setup文件树格式，例如：Expected dataset structure for COCO instance/keypoint detection

```
coco/
  annotations/
    instances_{train,val}2017.json
    person_keypoints_{train,val}2017.json
  {train,val}2017/
    # image files that are mentioned in the corresponding json
```

这应该放在指定的环境变量`DETECTRON2_DATASETS`中，默认为`./dataset`，可以通过`export DETECTRON2_DATASETS=/path/to/datasets`设置。

## Extend Detectron2’s Defaults

- 谈了谈Detectron2的基本设计思路。一方面要有足够的灵活性（做研究总是要做新东西），一方面要有较好的高层抽象（用户可以更好的操作）。
- 基本设计思路：所有的方法和类都可以从一个配置文件中获取所需要的参数（配置文件中没有的，就使用默认参数）。
- 介绍了扩展detectron2的一些相关文档
  - 使用自定义数据集: [Use Custom Datasets](https://detectron2.readthedocs.io/tutorials/datasets.html).
  - 自定义data loader from a dataset： [Use Custom Data Loaders](https://detectron2.readthedocs.io/tutorials/data_loading.html).
  - 使用标准模型和重写它的模型：[Use Models](https://detectron2.readthedocs.io/tutorials/models.html) and [Write Models](https://detectron2.readthedocs.io/tutorials/write-models.html).

  - 使用hooks自定义training loop： [training](https://detectron2.readthedocs.io/tutorials/training.html).

## Use Custom Datasets

使用了 `detectron2/data/catalog.py`中的  `DatasetCatalog`和`MetadataCatalog`。

> In my opinion, `DatasetCatalog`和`MetadataCatalog`都是Register对象（之后buildin的dataloader是基于这两个注册器对象的），这一步的目的就是将自定义的数据集注册到`DatasetCatalog/MetadataCatalog._obj_map`中。
>
> 因此这里还是保持register类的两个属性`_name`和`_obj_map`（组成字典），两个方法`register`和`get`(通过name获得obj_map)
>
> 获取已注册的dataset：`DatasetCatalog._REGISTERED`

1. **Register** your dataset：将数据集信息注册到`DatasetCatalog`，`_obj_map`的value为一个`get_dict`**方法**，该方法用于获取数据集，为一个 `list[dict]` 对象，每个字典就是一条输入数据：

   ```python
   def my_dataset_function():
     ...
     return list[dict] in the following format
   
   from detectron2.data import DatasetCatalog
   DatasetCatalog.register("my_dataset", my_dataset_function)
   ```

   对于标准任务，该数据集还需要在下游正确处理，因此需要标准的注释规范，具体的key列表（数据集的属性，file_name，annotations等）可以到文档中自己看[标准数据集字典](https://detectron2.readthedocs.io/tutorials/datasets.html#standard-dataset-dicts)；

   对于需要额外信息的新任务，也可以存储任意自定义的数据。为了确保下游代码可以正确处理该数据集，需要为`dataloader`重写一个新的`mapper`。

   【⚠️】每个字典旨在包含有关每个样本的少量但足够的信息，例如file_name和annotations

2. 选择性地**register metadata** for your dataset：【对于在整个数据集中共享的属性称之为元数据，如`names of classes, colors of classes, root of file`等】通过`MetadataCatalog.get(dataset_name).some_key = some_value`，将自定义数据集的**元数据**注册到`MetadataCatalog`中，内置的key见[数据集元数据](https://detectron2.readthedocs.io/tutorials/datasets.html#metadata-for-datasets)

---

* 注册coco数据集(coco格式的json文件)

```python
from detectron2.data.datasets import register_coco_instances
register_coco_instances("my_dataset", {}, "json_annotation.json", "path/to/image/dir")
```

* **注册了新数据集之后，还需要更新对应配置config**（各种类别数）

## Use Custom Dataloaders

`build_detection_{train,test}_loader`是**默认的dataloader**：

1. 用name加载数据集的list[dict]
2. 然后用`mapper`将每个dict映射为可供模型使用的格式（包括读图像，随机数据增强，转化为torch Tensors）。默认mapper是`DatasetMaper`，输出格式符合模型要求的输入格式。
3. mapper的输出被batched（放进一个list）
4. 输出。通常作为`model.forward()`的输入

---

**自定义dataloader**

```python
from detectron2.data import build_detection_train_loader
from detectron2.data import transforms as T
from detectron2.data import detection_utils as utils

def mapper(dataset_dict):
	# Implement a mapper, similar to the default DatasetMapper, but with your own customizations
	dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below
  # 读图像
	image = utils.read_image(dataset_dict["file_name"], format="BGR")
  # 调整图像为固定大小
	image, transforms = T.apply_transform_gens([T.Resize((800, 800))], image)
  # 转tensor
	dataset_dict["image"] = torch.as_tensor(image.transpose(2, 0, 1).astype("float32"))
	
	annos = [
    # 对单个instance的box/segmentation/keypoints实施transforms
		utils.transform_instance_annotations(obj, transforms, image.shape[:2])
		for obj in dataset_dict.pop("annotations")
		if obj.get("iscrowd", 0) == 0
	]
  # 创建Instance实例
	instances = utils.annotations_to_instances(annos, image.shape[:2])
  # 滤除空的
	dataset_dict["instances"] = utils.filter_empty_instances(instances)
	return dataset_dict

# load
data_loader = build_detection_train_loader(cfg, mapper=mapper)
# use this dataloader instead of the default
```

* 如果是用的DafaultTrainer，可以重写它的 `build_{train,test}_loader` 。以densepose的dataloader为例
* 如果是自定义循环，可以轻松插入dataloader

## Use Models

* 建立模型（这里建立模型结构并随机数填充）

```python
from detectron2.modeling import build_model
model = build_model(cfg)  # returns a torch.nn.Module
```

* 读取/保存checkpoint

```python
from detectron2.checkpoint import DetectionCheckpointer
DetectionCheckpointer(model).load(file_path_or_url)  # load a file, usually from cfg.MODEL.WEIGHTS

checkpointer = DetectionCheckpointer(model, save_dir="output")
checkpointer.save("model_999")  # save to output/model_999.pth
```

* 使用模型`outputs = model(inputs)`, 其中input 是 list[dict]，[Input格式](https://detectron2.readthedocs.io/tutorials/models.html#model-input-format)

—— 训练模式下，所有模型都必须在EventStorage中使用

```python
from detectron2.utils.events import EventStorage
with EventStorage() as storage:
  losses = model(inputs)
```

—— 如果要进行推理，可以用`DefaultPredictor`，或

```python
model.eval()
with torch.no_grad():
  outputs = model(inputs)
```

* 当需要中间值时有两种方法

  1. 编写子模型
  2. 执行部分模型，不用`forward()`，而是自定义代码


```python
images = ImageList.from_tensors(...)  # preprocessed input tensor
model = build_model(cfg)
# 自定义一步一步地执行
features = model.backbone(images.tensor)
proposals, _ = model.proposal_generator(images, features)
instances = model.roi_heads._forward_box(features, proposals)
mask_features = [features[f] for f in model.roi_heads.in_features]
mask_features = model.roi_heads.mask_pooler(mask_features, [x.pred_boxes for x in instances])
```

## Write Models

以添加新的backbone为例：

```python
from detectron2.modeling import BACKBONE_REGISTRY, Backbone, ShapeSpec

@BACKBONE_REGISTRY.register()
class ToyBackBone(Backbone):
  def __init__(self, cfg, input_shape):
    super().__init__()
    # create your own backbone
    self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=16, padding=3)

  def forward(self, image):
    return {"conv1": self.conv1(image)}

  def output_shape(self):
    return {"conv1": ShapeSpec(channels=64, stride=16)}
```

然后在config对象overwrite`cfg.MODEL.BACKBONE.NAME = 'ToyBackBone'`，之后的`build_model(cfg)`就是`ToyBackBone`了

再举一个例子，如果要在generalized 的RCNN中添加ROI head，可以实现一个新的 ROIHeads并将其放在`ROI_HEADS_REGISTRY`中。具体示例见project的densepose和meshrcnn。

---

完整的注册器列表见 [API documentation](https://detectron2.readthedocs.io/modules/modeling.html#model-registries)，可以自定义部分或全部模型。

## Train

见tools/{plain_}train_net.py。`TrainerBase`➡`SimpleTrainer`➡`DefaultTrainer`

* 如果自定义操作与`DefaultTrainer`相似，则继承`DefaultTrainer`，如train_net.py
* 如果需要其他东西，则参考plain_train_net.py实现

训练过程中，所有的metrics都保存在eventstorage中。EventWriter 可以将metrics写入目标位置

```python
from detectron2.utils.events import get_event_storage

# inside the model:
if self.training:
  value = # compute the value from inputs
  storage = get_event_storage()
  storage.put_scalar("some_accuracy", value)
  
  
# 或
from detectron2.utils.events import EventStorage
with EventStorage() as storage:
  losses = model(inputs)
```

## Evaluation

评价过程需要对输入输出进行匹配和汇总。

* 可以直接 [use the model](https://detectron2.readthedocs.io/tutorials/models.html) ，然后手动的执行评价。

```python
def get_all_inputs_outputs():
  for data in data_loader:
    yield data, model(data)

evaluator.reset()
for inputs, outputs in get_all_inputs_outputs():
  evaluator.process(inputs, outputs)
eval_results = evaluator.evaluate()
```

* 也可以使用`DatasetEvaluator`。`DatasetEvaluator`有一些针对标准数据集计算metrics的子类。也可以自定义其他功能，如计算有几个实例：

```python
class Counter(DatasetEvaluator):
  def reset(self):
    self.count = 0
  def process(self, inputs, outputs):
    for output in outputs:
      self.count += len(output["instances"])
  def evaluate(self):
    # save self.count somewhere, or print it, or return it.
    return {"count": self.count}
```

* 还可以和inference_on_dataset一起使用

```python
# 在data_loader上执行model，并用evaluator评估metrics。model将以eval mode执行，返回evaluator.evaluate()
eval_results = inference_on_dataset(
    model,
    data_loader,
    DatasetEvaluators([COCOEvaluator(...), Counter()]))
```

## Configs

- [x] 没什么问题

【⚠️】

1. 避免config重复，用`__BASE__`来共享配置之间的公共部分
2. config保持简洁，不要包含不影响实验的配置
3. 写config时，保留版本号如`VERSION: 2`，以免不兼容

# Colab Notebook

## **Install detectron2**

里面有一段测试

```python
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import cv2
import random
# from google.colab.patches import cv2_imshow

# import some common detectron2 utilities
from detectron2 import model_zoo	# 模型库
from detectron2.engine import DefaultPredictor	# 预测器
from detectron2.config import get_cfg	# 配置
from detectron2.utils.visualizer import Visualizer	# 可视化
from detectron2.data import MetadataCatalog	# 自定义dataset用的
```

## **Run a pre-trained detectron2 model**

- [x] demo-related
```python
# 创建配置（类似与argparse实例化一个对象）
cfg = get_cfg()
# 添加配置（from file，from list和直接添加）
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model
cfg.MODEL.DEVICES = 'cpu'

# 从model zoo中选在一个预训练的model及其配置文件，会返回一个url
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")

# 创建默认预测器
predictor = DefaultPredictor(cfg)	# 在engine里面
outputs = predictor(im)

# outputs['instances']包含了每个instance的类型, box, mask等信息
print(outputs["instances"].pred_classes)
print(outputs["instances"].pred_boxes)

# 可视化，（img_rgb, 元数据），[:, :, ::-1]把rgb顺序倒一转，因为cv2是bgr的
v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
# 在图像上绘制实例级预测结果。
v = v.draw_instance_predictions(outputs["instances"].to("cpu"))	
cv2_imshow(v.get_image()[:, :, ::-1])
```

## Train on a custom dataset

从coco与训练模型与训练balloon分割模型

### （一）prepare the dataset

```python
# 如果是coco格式的数据集，可以用以下三行代替（coco格式见buildin dataset）
# from detectron2.data.datasets import register_coco_instances
# register_coco_instances("my_dataset_train", {}, "json_annotation_train.json", "path/to/image/dir")
# register_coco_instances("my_dataset_val", {}, "json_annotation_val.json", "path/to/image/dir")

import os
import numpy as np
import json
from detectron2.structures import BoxMode

'''解析自定义数据（json格式的lable)'''
def get_balloon_dicts(img_dir):
    json_file = os.path.join(img_dir, "via_region_data.json")
    with open(json_file) as f:
        imgs_anns = json.load(f)

    dataset_dicts = []
    for idx, v in enumerate(imgs_anns.values()):
        record = {}
        
        filename = os.path.join(img_dir, v["filename"])
        height, width = cv2.imread(filename).shape[:2]
        
        record["file_name"] = filename
        record["image_id"] = idx
        record["height"] = height
        record["width"] = width
      
        annos = v["regions"]
        objs = []
        for _, anno in annos.items():
            assert not anno["region_attributes"]
            anno = anno["shape_attributes"]
            px = anno["all_points_x"]
            py = anno["all_points_y"]
            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]
            poly = [p for x in poly for p in x]

            obj = {
                "bbox": [np.min(px), np.min(py), np.max(px), np.max(py)],
                "bbox_mode": BoxMode.XYXY_ABS,
                "segmentation": [poly],
                "category_id": 0,
            }
            objs.append(obj)
        record["annotations"] = objs
        dataset_dicts.append(record)
    return dataset_dicts

from detectron2.data import DatasetCatalog, MetadataCatalog	# ./detectron2/data/catalog.py

# 注册训练和验证数据的数据集和元数据
for d in ["train", "val"]:
  	# train/val数据注册到DatasetCatalog中，保存一个字典{balloon_train/val:获得数据的方法}
    DatasetCatalog.register("balloon_" + d, lambda d=d: get_balloon_dicts("balloon/" + d))
    # 将新数据的元数据注册到MetadataCatalog中：为新数据添加元数据，并定义我们要到的类别
    MetadataCatalog.get("balloon_" + d).set(thing_classes=["balloon"])
    
# 访问ballon_train的元数据。（register对象.get可以直接调用定义的类） -> 用于visualize
balloon_metadata = MetadataCatalog.get("balloon_train")
```

### （二）Train

```python
from detectron2.engine import DefaultTrainer	# engine里主训练评估
from detectron2.config import get_cfg					# config里主配置

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("balloon_train",)
cfg.DATASETS.TEST = ()
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")  # Let training initialize from model zoo
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR
cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg) 
trainer.resume_or_load(resume=False)
trainer.train()
```

+ 用tensorboard看training curves

### （三）Inference & evaluation

```python
cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model
cfg.DATASETS.TEST = ("balloon_val", )
predictor = DefaultPredictor(cfg)

# 随机选择几个样本来可视化预测结果
from detectron2.utils.visualizer import ColorMode
dataset_dicts = get_balloon_dicts("balloon/val")
for d in random.sample(dataset_dicts, 3):    
    im = cv2.imread(d["file_name"])
    # 预测
    outputs = predictor(im)
    # 可视化
    v = Visualizer(im[:, :, ::-1],
                   metadata=balloon_metadata, 
                   scale=0.8, 
                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels
    )
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(out.get_image()[:, :, ::-1])
    
# 用AP metric指标评估其性能（average precision和average Recall）
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader
# evaluator
evaluator = COCOEvaluator("balloon_val", cfg, False, output_dir="./output/")
# evaldataset
val_loader = build_detection_test_loader(cfg, "balloon_val")
# eval
inference_on_dataset(trainer.model, val_loader, evaluator)
# another equivalent way is to use trainer.test；同样可以使用trainer.test
```

## Other types of builtin models

包括关键点，全景分割和全景分割on video。

# 源码理解

> **代码逻辑分析**：detectron2将模型拆分为多个模块，通过配置文件来选择对应的模块搭建模型。

## （一）Config&Trainer

`Detectron2`的大致逻辑：

1. **超参数配置**

使用`yacs`库，能够很好地重用和拼接超参数文件配置。

- 默认配置文件： `./detectron2/config/defaults.py` 
- 实例配置文件： `./configs`文件夹中，yaml格式（实例配置在默认配置的基础上，继承`_BASE_`属性只想的实例文件，冲突使用当前）

2. **Trainer**

`./tools`里有两个文件：

* `train_net.py`里定义了一个继承自`./detectron2.engine.default.DefaultTrainer`的Trainer，这个父类会自动解析cfg，之后调用`trainer.train()`就可以开始训练了。
* `plain_train_net.py`则更多的自定义模型，优化函数等

## （二）Registry&build_*方法

要了解`DefaultTrainer`是如何解析cfg的，需要了解`detectron2`的`Registry`机制，和`DefaultTrainer`类中的各种`build_*`函数

1. **build_*方法**

在`DefaultTrainer`的`__init__(self, cfg)`函数中，定义了若干个`build_*`方法，解析cfg，得到解析后的model,optimizer,data_loader等。下面以`build_model`为例：

该方法调用了`detectron2/modeling/meta_arch/build_model.py`的`build_model`函数，源代码如下：

```python
from detectron2.utils.registry import Registry

META_ARCH_REGISTRY = Registry("META_ARCH")  # noqa F401 isort:skip
META_ARCH_REGISTRY.__doc__ = """
Registry for meta-architectures, i.e. the whole model.

The registered object will be called with `obj(cfg)`
and expected to return a `nn.Module` object.
"""


def build_model(cfg):
    """
    Build the whole model architecture, defined by ``cfg.MODEL.META_ARCHITECTURE``.
    Note that it does not load any weights from ``cfg``.
    """
    meta_arch = cfg.MODEL.META_ARCHITECTURE	# 根据超参数获得网络结构的名字
    model = META_ARCH_REGISTRY.get(meta_arch)(cfg)	# 其中META_ARCH_REGISTRY是一个Register类
    model.to(torch.device(cfg.MODEL.DEVICE))
    return model
```

2. **Registry机制**

`Registry`源代码如下（有删减），来自于`fvcore.common.registry.Registry`：

```Python
class Registry(object):
    def __init__(self, name):
        self._name = name
        self._obj_map = {}

    def _do_register(self, name, obj):
        assert (
            name not in self._obj_map
        ), "An object named '{}' was already registered in '{}' registry!".format(name, self._name)
        self._obj_map[name] = obj

    def register(self, obj=None):
        if obj is None:
            # used as a decorator
            def deco(func_or_class):
                name = func_or_class.__name__
                self._do_register(name, func_or_class)
                return func_or_class

            return deco

        # used as a function call
        name = obj.__name__
        self._do_register(name, obj)

    def get(self, name):
        ret = self._obj_map.get(name)
        if ret is None:
            raise KeyError("No object named '{}' found in '{}' registry!".format(name, self._name))
        return ret
```

* **两个属性**：

  * `self._name`是要注册的**名字**，对于完整模型，name为META_ARCH，对于backbone，name为BACKBONE；
  * `self._obj_map`是一个字典，**key为模型名字(*不是对象的名字*)，value为对应的模型**。

* **两个方法**（`register`和`get`，其中`register`调用`_do_register`）：

  * `register`：定义了如上两种注册方式，1) 对象不存在`obj==None`，使用装饰器`@registry_object.register`修饰；2) 对象存在，直接调用`_do_register`。**因此`_do_register`是真正的注册函数。**它会先判断`name`是否已存在于`_obj_map`，没有的话，就把这个name加到`_obj_map`这个dict中。

    > 还是以backbone为例，我们定义了一个`BACKBONE_REGISTRY = Registry('BACKBONE')`,然后又定义了很多种backbone，而这些backbone都使用`@BACKBONE_REGISTRY.register()`的方式注册到了`BACKBONE_REGISTRY._obj_map`中

  * `get`：可以通过`对象.get(方法)`的办法来间接的调用被注册的函数，其实就是根据key取值value。

这样，可以方便的根据配置文件，传参时不同的名字就能直接创建对应的对象。

---

**在detectron2中**

- 每个类型的modeling都包含一个Registry对象。如backbone, anchor generator, proposal generator, roi head等，见 `detectron2/modeling/` 。
- 大的Registry（由一个包组成）对应一个**build.py**，根据`*_REGISTRY._obj_map`这个dict，通过name获取对应模型，然后将示例配置文件中参数导入目标模型中。

> 以实现新的backbone网络为例：
>
> 1） 首先定义一个名字为backbone的register类（detectron2自带）
>
> ```python
> # detectron2/modeling/backbone/build.py
> BACKBONE_REGISTRY = Registry('BACKBONE')
> ```
>
> 2) 然后在创建的新文件下，以如下方式创建自定义的backbone（detectron2中自带fpn和resnet，resnet比较完整【**可参考**】）
>
> ```python
> # detectron2/modeling/backbone/your_backbone.py
> from .build import BACKBONE_REGISTRY
> 
> # 方式1
> @BACKBONE_REGISTRY.register()
> class MyBackbone():
> 	...
> 		
> # 方式2
> class MyBackbone():!
> 	...
> BACKBONE_REGISTRY.register(MyBackbone)
> ```

## （三）Dataset pipeline

构建data_loader的两个重要函数`build_detection_{train/test}_loader`在`./data/build.py`，它们的输出是model的输入。以`build_detection_train_loader`为例

```python
def build_detection_train_loader(cfg, mapper=None):
    """
    A data loader is created by the following steps:

    1. Use the dataset names in config to query :class:`DatasetCatalog`, and obtain a list of dicts.
    2. Start workers to work on the dicts. Each worker will:
      * Map each metadata dict into another format to be consumed by the model.
      * Batch them by simply putting dicts into a list.
    The batched ``list[mapped_dict]`` is what this dataloader will return.

    Args:
        cfg (CfgNode): the config
        mapper (callable): a callable which takes a sample (dict) from dataset and
            returns the format to be consumed by the model.
            By default it will be `DatasetMapper(cfg, True)`.

    Returns:
        a torch DataLoader object
    """
	# 获得dataset_dicts
    dataset_dicts = get_detection_dataset_dicts(
        cfg.DATASETS.TRAIN,
        filter_empty=True,
        min_keypoints=cfg.MODEL.ROI_KEYPOINT_HEAD.MIN_KEYPOINTS_PER_IMAGE
        if cfg.MODEL.KEYPOINT_ON
        else 0,
        proposal_files=cfg.DATASETS.PROPOSAL_FILES_TRAIN if cfg.MODEL.LOAD_PROPOSALS else None,
    )
	
	# 将dataset_dicts转化成torch.utils.data.Dataset
    dataset = DatasetFromList(dataset_dicts, copy=False)

	# 进一步转化成MapDataset，每次读取数据时都会调用mapper来对dict进行解析
    if mapper is None:
        mapper = DatasetMapper(cfg, True)
    dataset = MapDataset(dataset, mapper)
	
	# 采样器
    sampler_name = cfg.DATALOADER.SAMPLER_TRAIN
    if sampler_name == "TrainingSampler":
        sampler = samplers.TrainingSampler(len(dataset))
		...
    batch_sampler = build_batch_data_sampler(
        sampler, images_per_worker, group_bin_edges, aspect_ratios
    )
	
	# 数据迭代器 data_loader
    data_loader = torch.utils.data.DataLoader(
        dataset,
        num_workers=cfg.DATALOADER.NUM_WORKERS,
        batch_sampler=batch_sampler,
        collate_fn=trivial_batch_collator,
        worker_init_fn=worker_init_reset_seed,
    )
    return data_loader
由源代码可知，构建dataloader共五个步骤：
```
* 第一步，获得dataset_dicts。根据dataset_names，调用`DatasetCatalog`来进行解析得到一个包含数据信息的字典列表 - list[dict]。

  ```python
  from detectron2.data import DatasetCatalog
  my_dataset_name = 'apple'
  def get_dicts():
  	...
  	return dict
  
  DatasetCatalog.register(my_dataset_name, get_dicts)
  DatasetCatalog.get()	# 返回刚刚注册的get dict函数
  ```

  如果数据集已经是coco格式，那么用如下方法注册：

  ```python
  from detectron2.data.datasets import register_coco_instances
  my_dataset_name = 'apple'
  register_coco_instances(my_dataset_name, {}, "json_annotation.json", "path/to/image/dir")
  ```

  数据集由两个类定义，除了`datasetcatalog`，还有`MetadataCatalog`记录元数据。

  在注册`datasetcatalog`后，我们还可以对`metadatacatalog`进行注册，定义我们可能用到的属性特征：

  ```python
  from detectron2.data import MetadataCatalog
  MetadataCatalog.get("my_dataset").thing_classes = ["person", "dog"]
  
  # 也可以这样
  MetadataCatalog.get("my_dataset").set("thing_classes",["person", "dog"])
  ```

* 第二步，将dataset_dicts转化成`torch.utils.data.Dataset`。在`detectron2/data/common.py`中，继承于`torch.utils.data.Dataset`。转换之后支持索引(dataset[i]读单个数据)

  ```python
  class DatasetFromList(data.Dataset):
      """
      Wrap a list to a torch Dataset. It produces elements of the list as data.
      """
  
      def __init__(self, lst: list, copy: bool = True):
          """
          Args:
              lst (list): a list which contains elements to produce.
              copy (bool): whether to deepcopy the element when producing it,
                  so that the result can be modified in place without affecting the
                  source in the list.
          """
          self._lst = lst
          self._copy = copy
  
      def __len__(self):
          return len(self._lst)
  
      def __getitem__(self, idx):
          if self._copy:
              return copy.deepcopy(self._lst[idx])
          else:
              return self._lst[idx]
  ```

* 第三步，进一步转化成MapDataset，每次读取数据时都会调用mapper来对dict进行解析，将每个dict映射为可供模型使用的格式，主要工作包括读取图像、resize、crop、flip、转换数据与标签的形式等。

  默认的mapper为DatasetMapper，源码如下（有删减）

  ```python
  class DatasetMapper:
      def __init__(self, cfg, is_train=True):
  		# 读取cfg的参数
  		...
  
      def __call__(self, dataset_dict):
          """
          Args:
              dataset_dict (dict): Metadata of one image, in Detectron2 Dataset format.
  
          Returns:
              dict: a format that builtin models in detectron2 accept
          """
          dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below
  		
  		# 1. 读取图像数据
          image = utils.read_image(dataset_dict["file_name"], format=self.img_format)
  		
  		# 2. 对image和box等做Transformation
          if "annotations" not in dataset_dict:
              image, transforms = T.apply_transform_gens(
                  ([self.crop_gen] if self.crop_gen else []) + self.tfm_gens, image
              )
          else:
  			...
              image, transforms = T.apply_transform_gens(self.tfm_gens, image)
              if self.crop_gen:
                  transforms = crop_tfm + transforms
  ```

  `MapDataset`还是继承自`data.Dataset`，调用mapper（map_func）来转换数据（返回还是Dataset）

  ```python
  class MapDataset(data.Dataset):
      def __init__(self, dataset, map_func):
          self._dataset = dataset
          self._map_func = PicklableWrapper(map_func)  # wrap so that a lambda will work
  
          self._rng = random.Random(42)
          self._fallback_candidates = set(range(len(dataset)))	# 这个set可以实现去重
  
      def __len__(self):
          return len(self._dataset)
  
      def __getitem__(self, idx):
      '''
      __getitem__和self._fallback_candidates配合，将能够正常通过map_func的数据加入到_fallback_candidates中去，否则丢弃。
      '''
          retry_count = 0
          cur_idx = int(idx)
  
          while True:
              data = self._map_func(self._dataset[cur_idx])
              if data is not None:
                  self._fallback_candidates.add(cur_idx)
                  return data
  
              # _map_func fails for this idx, use a random new index from the pool
              retry_count += 1
              self._fallback_candidates.discard(cur_idx)
              cur_idx = self._rng.sample(self._fallback_candidates, k=1)[0]
  
              if retry_count >= 3:
                  logger = logging.getLogger(__name__)
                  logger.warning(
                      "Failed to apply `_map_func` for idx: {}, retry count: {}".format(
                          idx, retry_count
                      )
                  )
  ```

* 第四步，生成采样器。构建`torch.utils.data.sampler.Sampler`对象，包括Repeat Sample、shuffle、batch功能。

* 第五步，生成数据迭代器data_loader。

# 源码阅读笔记

## 数据处理

<img src="https://i.loli.net/2020/06/17/Y7mPbOdVIkT2DyM.png" alt="image-20200617101826563" style="zoom:50%;" />

* 实现功能：通过配置文件即可实现数据集解析、预处理、增强等操作。
* 相关代码：主要位于 `detectron2/detectron2/data` 目录下。
* 主要入口： `detectron2/data/build.py` 中的 `build_detection_{train/test}_loader`方法。
* 相关配置：`detectron2/config/defaults.py` 中 `_C.INPUT _C.DATASETS _C.DATALOADER` 开头的配置。

【其他】

* 数据增强，主要在`detectron2/detectron2/data/transforms/transform_gen.py` 中定义，调用主要是通过 `from detectron2.data import transforms as T` 然后 `T.ResizeShortestEdge` 来实现。

---

**基本流程**：见[build_detection_train_loader](##（三）Dataset pipeline)

1. 注册数据集（包括dataset和metadata）：`DatasetCatalog.register(dataset_name, get_dict_func)`&`MetadataCatalog.get(dataset_name).set(name, value)`。

   > `detectron2`中有注册一些常用数据集，在`detectron2/detectron2/data/datasets/builtin.py`中

2. 通过`dataset name`和`DatasetCatalog`，获得 a list of dicts。

   > 默认的方法是build.py中的get_detection_dataset_dicts

3. 通过`mapper`转换数据，包括：

   * 将原始数据转化为可供模型使用的数据格式（Dataset）

   * 各种预处理

4. batch them & 生成dataloader

## 模型搭建

<img src="https://i.loli.net/2020/06/17/ynYRWUTDdfz9o6G.png" alt="image-20200617105329213" style="zoom:50%;" />

- 实现功能：通过配置文件构建模型。
- 主要入口：`detectron2/detectron2/modeling/meta_arch/build.py` 中的 `def build_model(cfg)` 方法。
- 相关代码：`detectron2/detectron2/modeling` 目录下。
- 相关配置：`detectron2/config/defaults.py`中`_C.MODEL` 开头的配置。

【其他】

* 模型相关Registry对象列表
  * `ANCHOR_GENERATOR_REGISTRY`：如何生成anchors。
  * `BACKBONE_REGISTRY`：主干网络，包括FPN。
  * `META_ARCH_REGISTRY`：基本网络，总体结构。
  * `SEM_SEG_HEADS_REGISTRY`：应该是用来做语义分隔的。
  * `PROPOSAL_GENERATOR_REGISTRY`：Faster RCNN中的Region proposal Network，即如何生成proposals。
  * `RPN_HEAD_REGISTRY`：第一阶段训练所需的输入。
  * `ROI_BOX_HEAD_REGISTRY`：ROI Head中的bbox分支。
  * `ROI_HEADS_REGISTRY`：通过特征图和第一阶段的proposals得到ROI。
  * `ROI_KEYPOINT_HEAD_REGISTRY`：ROI Head中的keypoint分支。
  * `ROI_MASK_HEAD_REGISTRY`：ROI Head中的mask分支。

---

**基本流程**：以`./modeling/meta_arch/rcnn.py/GeneralizedRCNN`为例，继承`nn.module`，包括最基本的`__init__`和`forward`定义网络结构：

1. 在`layers`和`modeling`中搭建好各种网络结构，并注册到 Registry 对象中。
2. 注册模型的基本框架(meta arch)，detectron2中自带了 rcnn, retinanet, semantic seg, panoptic 。
3. 根据配置文件，分别构建选中meta arch中各个部件。

## 模型训练、预测、评估

<img src="https://i.loli.net/2020/06/17/K3V47dyDkqpojmS.png" alt="image-20200617113553794" style="zoom:50%;" />

* 实现功能：模型存取、优化器、学习率、损失函数、性能指标、TensorBoard等。
* 主要入口：`detectron2/detectron2/engine/defaults.py` 中的 `DefaultTrainer, DefaultPredictor`。
* 相关代码：主要在 `detectron2/detectron2/engine` 和 `detectron2/detectron2/solver` 中
* 相关配置：`detectron2/config/defaults.py`中`_C.SOLVER _C.TEST` 开头的配置。

---

**train** ➡ `DefaultTrainer`

**predict** ➡ `DefaultPredictor`

**evaluate** ➡ predict+手动eval || `DatasetEvaluator`

# 如何实现

如果基于如下的几个需求：

> 1、需要定义自己的data_loader， 以加载自己的数据集 
> 2、针对自己的训练任务，有自己的评价方法，而希望边训边测试，所以需要定义自己的EvalHook，并在Trainer中调用，这时候就需要自定义 自己的 register_hook 方法
> 3、在数据加载时，需要对数据进行debug，因此需要自定义自己的run_step 方法
> 4、因为进行简单调试的时候，经常容易训练出nan，因此需要定义自己的_detect_anomaly 方法

就可以**继承DefaultTrainer**， 并重写相关的方法，进行自定义即可。





1. 加载自己的数据集

重写 `build_train_loader`

2. 自定义Trainer类



# 感想

* project里的代码非常简洁

<img src="https://i.loli.net/2020/06/18/3L4ugIajDCb1WGl.png" alt="image-20200618105009630" style="zoom:50%;" />


# **Reference**

[官方Tutorial](https://detectron2.readthedocs.io/tutorials/index.html)

[Colab Notebook](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5)

[API文档](https://detectron2.readthedocs.io/modules/index.html)

[Detectron2源码阅读笔记](https://www.cnblogs.com/marsggbo)（对应[知乎专栏](https://zhuanlan.zhihu.com/automl)）

- [Detectron2源码阅读笔记-(一)Config&Trainer](https://www.cnblogs.com/marsggbo/p/11677086.html)
- [Detectron2源码阅读笔记-(二)Registry&build_*方法](https://www.cnblogs.com/marsggbo/p/11678371.html)
- [Detectron2源码阅读笔记-（三）Dataset pipeline](https://www.cnblogs.com/marsggbo/p/11727556.html)

[Detectron2 源码浏览](https://zhuanlan.zhihu.com/p/98799433)

[知乎专栏 - detectron2项目指北](https://zhuanlan.zhihu.com/c_1167741072251305984)

* [[Detectron2]04-Trainer/Hooks](https://zhuanlan.zhihu.com/p/97326458)

