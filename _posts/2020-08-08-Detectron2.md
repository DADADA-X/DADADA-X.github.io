---
layout:     post
title:      "Detectron2 ä»£ç ç¬”è®°"
date:       2020-08-08 10:00:00
author:     "DadaX"
tags:
    - æ·±åº¦å­¦ä¹ 
---

# Detectron2 ä»£ç ç»“æ„

<img src="https://i.loli.net/2020/06/28/YqP3D9GfbBWyJSu.png" alt="image-20200615162825673.png" style="zoom:40%;" />

<center>ä»£ç ç»“æ„
</center>

![image-20200617093312363](https://i.loli.net/2020/06/17/gOd3FeDmScKMk9W.png)

<center>è°ƒç”¨å…³ç³»
</center>
**æ ¸å¿ƒéƒ¨åˆ†**

- `configs`ï¼šå®ä¾‹**yamlé…ç½®æ–‡ä»¶**åˆé›†ã€‚

- `datasets`ï¼š**æ•°æ®é›†å‡†å¤‡**å·¥ä½œï¼Œä¸»è¦æ˜¯readme.mdâ¡ä»‹ç»å„ä¸ªæ•°æ®é›†çš„åŸºæœ¬ç»“æ„ï¼Œä»¥åŠéœ€è¦å¦‚ä½•é¢„å¤„ç†ã€‚|| å­˜æ”¾æ•°æ®é›†çš„åœ°æ–¹ï¼ˆéœ€è¦è‡ªå·±æ”¾ï¼‰

- `tools`ï¼šå¸¸ç”¨è„šæœ¬ï¼Œå¦‚è®­ç»ƒã€benchmarkã€å¯è§†åŒ–ç­‰ï¼Œæ¯”è¾ƒé‡è¦çš„æ˜¯`train_net.py`å’Œ`plain_train_net.py`ï¼Œå¯ä»¿ç…§ã€‚

- `detectron2`ï¼šé¡¹ç›®ä¸»è¦ä»£ç éƒ½åœ¨è¿™é‡Œäº†ï¼Œé‡è¦çš„æ–‡ä»¶æœ‰ï¼š

  - `config`ï¼šè¶…å‚æ•°é…ç½®ï¼Œæœ‰ä¸¤ä¸ªé‡è¦æ–‡ä»¶

    - `config.py`ï¼šå®šä¹‰äº†`CfgNode`ç±»ï¼Œç»§æ‰¿äº`fvcore`åº“çš„`CfgNode`ï¼Œåˆç»§æ‰¿äº`yacs`åº“çš„`CfgNode`ï¼›è¿˜æä¾›äº†`get_cfg()`æ–¹æ³•ï¼Œä¼šè¿”å›ä¸€ä¸ªå«æœ‰é»˜è®¤é…ç½®çš„`CfgNode`ã€‚
  - `default.py`ï¼šé»˜è®¤é…ç½®æ–‡ä»¶ã€‚
    
  - ğŸŒŸ`engine`ã€‚

    - `launch.py`ï¼šä»£ç å¯åŠ¨å™¨ï¼Œå¯ä»¥æ ¹æ®å‘½ä»¤å†³å®šæ˜¯å¦é‡‡ç”¨åˆ†å¸ƒå¼è®­ç»ƒï¼ˆæˆ–è€…å•æœºå¤šå¡ï¼‰æˆ–è€…å•æœºå•å¡è®­ç»ƒã€‚
    - `train_loop.py`æä¾›äº†ä¸‰ä¸ªé‡è¦çš„ç±»ï¼š**1)** `HookBase`ï¼šHookçš„åŸºç±»ï¼Œç”¨äºæŒ‡å®šè®­ç»ƒå‰åæˆ–æ¯ä¸ªstepå‰åéœ€è¦åšä»€ä¹ˆäº‹ï¼Œæœ‰`before_train`, `after_train`, `before_step`, `after_step ` å››ä¸ªå‡½æ•°ï¼›**2)** `TrainerBase`ï¼šTrainerçš„åŸºç±»ï¼Œæœ‰ä¸‰ç§å‡½æ•°ï¼šâ‘ `register_hooks`å°†ç”¨æˆ·å®šä¹‰çš„ä¸€äº›hooksè¿›è¡Œæ³¨å†Œï¼Œå°±æ˜¯æŠŠhookä¸Šåˆ°ä¸€ä¸ªlisté‡Œï¼Œä¹‹åéå†è¿™ä¸ªlistå°±è¡Œäº† â‘¡`train`å‡½æ•°ï¼šæ‰§è¡Œâ‘¢ä¸­çš„æ­¥éª¤ï¼› â‘¢ å¯¹äºå¦‚ä½•éå†hook listï¼Œæœ‰1)ä¸­æåˆ°çš„å››ç§æ–¹å¼ï¼Œ`before_train`, `after_train`, `before_step`, `after_step`ï¼›è¿˜æœ‰ä¸€ä¸ªå°±æ˜¯`run_step`ï¼Œå°±æ˜¯å¹³å¸¸æˆ‘ä»¬åœ¨ç¼–å†™è®­ç»ƒè¿‡ç¨‹çš„ä»£ç ï¼Œä¾‹å¦‚è¯»æ•°æ®ï¼Œè®­ç»ƒæ¨¡å‹ï¼Œè·å–æŸå¤±å€¼ï¼Œæ±‚å¯¼æ•°ï¼Œåå‘æ¢¯åº¦æ›´æ–°ç­‰ï¼Œè¿™é‡Œæ²¡å®šä¹‰ï¼›**3)** `SimpleTrainer`ï¼šç»§æ‰¿`TrainerBase`ï¼Œå®šä¹‰äº†`run_step`ï¼Œåé¢å¯ä»¥ç»§æ‰¿è¿™ä¸ªç±»åšè¿›ä¸€æ­¥çš„è‡ªå®šä¹‰ã€‚

    * `hooks.py`ï¼šå®šä¹‰äº†å¾ˆå¤šç»§æ‰¿è‡ª`HookBase`çš„Hook

    - `defaults.py`æä¾›äº†ä¸¤ä¸ªç±»ï¼š`DefaultPredictor`å’Œ`DefaultTrainer`ï¼Œå…¶ä¸­`DefaultTrainer`å°±ç»§æ‰¿è‡ª`SimpleTrainer`ï¼Œé‡Œé¢åŒ…å«äº†å¾ˆå¤šå¯ä»¥å¯ä»¥è‡ªå®šä¹‰çš„å‡½æ•°ï¼Œå¦‚`build_model, build_optimizer, build_lr_scheduler`ç­‰ï¼›ä¸¤ä¸ªå‡½æ•°`default_argument_parser`å’Œ`default_setup`

    > æ€»è€Œè¨€ä¹‹ï¼Œengineæä¾›è®­ç»ƒ/é¢„æµ‹/è¯„ä¼°ç›¸å…³çš„ä¸»è¦ä»£ç ï¼Œæœ€é‡è¦çš„æ˜¯æä¾›äº†`DefaultPredictor`å’Œ`DefaultTrainer`ï¼Œä»¥åŠç”¨hookæ„å»ºtrainerçš„æ–¹å¼ï¼š
    >
    > * `HookBase`â¡`hooks.py`é‡Œå„ç§ç±»ï¼Œå¦‚è¯»æ•°æ®ï¼Œè®­ç»ƒæ¨¡å‹ï¼Œè·å–æŸå¤±å€¼ï¼Œæ±‚å¯¼æ•°ï¼Œåå‘æ¢¯åº¦æ›´æ–°ç­‰
    >
    > * `TrainerBase`â¡`SimpleTrainer`â¡`DefaultTrainer`â¡è‡ªå®šä¹‰çš„trainer
    >

  - `layers`ï¼šç”¨äºæ„å»ºmodelingçš„åŸºæœ¬å•å…ƒ â¡ ğŸŒŸ`modeling`ï¼šè‡ªå®šä¹‰æ¨¡å‹

  - ğŸŒŸ`data`ï¼šå®šä¹‰dataloaderï¼Œå¯å‚è€ƒ`build.py\build_detection_train_loader(cfg)`

    - **`datasets`**ï¼šä¸»è¦è´Ÿè´£å®šä¹‰å„ä¸ªæ•°æ®é›†çš„å…·ä½“çš„åŠ è½½åˆ†ææ–¹æ³•
    - sampler è´Ÿè´£dataloader ç”Ÿæˆbatch æ•°æ®æ—¶å¯¹dataset çš„æŠ½æ ·æ–¹æ³•
    - transforms å°±è´Ÿè´£è®°å½•æ‰€æœ‰çš„æ•°æ®å¢å¼ºæ“ä½œ
    - **`build.py`**ï¼š è´Ÿè´£ build_detection_data_loader ,
    - catalog.py ä¸­å®šä¹‰äº† DatasetCatalog å’Œ MetaCatalog ï¼Œ åè€…ç”¨äºå¯¹æ¯ä¸ªæ•°æ®é›†è®°å½•å…ƒä¿¡æ¯ï¼Œå¦‚æ¯ä¸ªç±»åˆ«idxå¯¹åº”ä»€ä¹ˆå…·ä½“ç±»åˆ«ç­‰
    - common.py å®šä¹‰äº†MapDataset ï¼Œ å³ä¸Šæ–‡ä¸€ç›´åœ¨è¯´çš„MyDataset
    - dataset_mapper ä¸­å®šä¹‰äº†MapFunc ç±»ï¼Œ ç”¨äºè¿›è¡Œæ•°æ®çš„å¢å¼ºå’Œæ ‡ç­¾çš„å¤„ç†

  - `solver`ï¼šå®šä¹‰äº†optimizerå’Œlr_scheduler || `utils`ï¼šå·¥å…·ï¼ŒåŒ…æ‹¬Registry

**Tutorialéƒ¨åˆ†**

- `demo`ï¼šé‡Œé¢æœ‰ä¸€ä¸ªç”¨äºé¢„æµ‹çš„`demo.py`ï¼Œé¢„æµ‹å’Œå¯è§†åŒ–éƒ½å°è£…åœ¨`predictor.py`
- `docs`ï¼šæ˜¯detectron2çš„å®˜æ–¹documentation
- `projects`ï¼šåŸºäºDetectron2çš„é¡¹ç›®ï¼ŒDensePose/PointRend/TensorMask/TridentNet
- åœ¨çŸ¥ä¹é‡Œï¼ŒDetectron2çš„å¼€å‘äººå‘˜ä»‹ç»ï¼Œå¦‚æœæƒ³è¦åˆ©ç”¨detectron2ç›´æ¥å¤ç°æ‰€æœ‰è®ºæ–‡å¯èƒ½æ¯”è¾ƒå›°éš¾ï¼ˆæˆ‘çš„ç†è§£å°±æ˜¯ç›´æ¥ä¿®æ”¹detectron2ä¸­çš„ä»£ç ï¼‰ï¼Œä¸€ç§æ¯”è¾ƒå¥½çš„æ–¹å¼å°±æ˜¯å°†detectron2ä½œä¸ºä¸€ä¸ªåŒ…æ¥è°ƒç”¨æ¥æ„å»ºæ–°çš„æ¨¡å‹ã€‚
  - è¿™é‡Œçš„ä¸‰ä¸ªé¡¹ç›®å°±æ˜¯åˆ©ç”¨detectron2å¤ç°æ¨¡å‹çš„ç¤ºä¾‹ã€‚ã€**ä¹‹åè‡ªå·±çš„ä»£ç ç»“æ„çœ‹å‚è€ƒè¿™ä¸ªç»“æ„å†™**ã€‘
- `tests`ï¼šæä¾›äº†ä¸€äº›æµ‹è¯•ä»£ç 
  - `train_net.py`/`plain_train_net.py`ï¼š**ã€è‡ªå·±å†™trainæ—¶å¯å‚è€ƒã€‘**

# å®˜æ–¹Tutorials

## Install

- [x] å®‰è£…ï¼Œæ²¡ä»€ä¹ˆé—®é¢˜

å®˜ç½‘æœ‰ä¸¤ç§å®‰è£…æ–¹å¼

```
python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'
# (add --user if you don't have permission)

# Or, to install it from a local clone:
git clone https://github.com/facebookresearch/detectron2.git
python -m pip install -e detectron2
```

æ–¹æ³•2åº“åœ¨cloneä¸‹æ¥çš„åœ°æ–¹ï¼Œä¸ä¼šæ”¾è¿›`./miniconda/env/detectron2/lib/python3.8/site-package`é‡Œï¼Œå› æ­¤å¦‚æœæ”¹å˜äº†ä½ç½®ï¼Œå°±è¦é‡æ–°æ‰§è¡Œ`python -m pip install -e detectron2`

>python -m mode : run library module as a script(terminates option list) è¿è¡Œæ¨¡å—åº“as aè„šæœ¬
>
>pip -e                     : install a project in editable mode(i.e. setuptools "develop mode") from a local project path or a VCS url å®‰è£…projectä»local projectæˆ–è€…url

å‚è€ƒ`solaris`çš„æ–¹æ³•ï¼Œè¿›å…¥cloneçš„ä»“åº“ï¼Œå†æ‰§è¡Œ`pip install .`åˆ™ä¼šåœ¨`site-package`é‡Œç”Ÿæˆ`detectron2`ï¼Œcloneçš„ä»“åº“detectron2å°±å¯ä»¥éšä¾¿åŠ¨äº†>.<

## Get Started With Detectron2

- [x] **å®˜æ–¹demo**

ä¼šæŠŠå‚æ•°è§£æ`def get_parser():`å’Œé…ç½®è®¾ç½®`def setup_cfg(args):`å°è£…ä¹˜å‡½æ•°

>  To run **on cpu**, add `MODEL.DEVICE cpu` after `--opts`. Like: `python demo.py --opts MODEL.DEVICE cpu`

```python
def setup_cfg(args):
    # load config from file and command-line arguments
    cfg = get_cfg()
    cfg.merge_from_file(args.config_file)
    cfg.merge_from_list(args.opts)
    # Set score_threshold for builtin models
    cfg.MODEL.RETINANET.SCORE_THRESH_TEST = args.confidence_threshold
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = args.confidence_threshold
    cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = args.confidence_threshold    
		cfg.freeze()	# è®©é…ç½®ä¸èƒ½å†è¢«ä¿®æ”¹ï¼Œå¼ºè¡Œä¿®æ”¹ä¼šæŠ¥AttributeErrorè¯´CfgNode is immutable
    return cfg
```

å¦å¤–detectron APIè¿˜å°è£…äº†cv2è¯»å›¾åƒçš„å‡½æ•°

```python
from detectron2.data.detection_utils import read_image
```

æŠŠé¢„æµ‹å’Œå¯è§†åŒ–éƒ½å°è£…è¿›äº†`predictor.py`ï¼Œç›´æ¥å®ä¾‹åŒ–ä¸€ä¸ªdemoï¼Œè°ƒç”¨å‡½æ•°run_on_imageå°±è¡Œäº†

- [x] **train_net & plain_train_net**

* train_net

é¦–å…ˆéœ€è¦å‡†å¤‡è®­ç»ƒç”¨çš„æ•°æ®é›†ã€‚following [datasets/README.md](https://github.com/facebookresearch/detectron2/blob/master/datasets/README.md)

é¦–å…ˆï¼Œ`def setup(args)`ï¼Œå®šä¹‰è¶…å‚æ•°é…ç½®å‡½æ•°ï¼š

```python
def setup(args):
    """
    Create configs and perform basic setups.
    """
    cfg = get_cfg()	# è·å–å·²ç»é…ç½®å¥½é»˜è®¤å‚æ•°çš„cfg
    cfg.merge_from_file(args.config_file)	# å°†yamlæ–‡ä»¶ä¸­æŒ‡å®šçš„è¶…å‚æ•°å¯¹é»˜è®¤å€¼è¿›è¡Œè¦†ç›–
    cfg.merge_from_list(args.opts)	# é€šè¿‡å‘½ä»¤è¡Œä¸­optså‚æ•°ä¸­çš„æŒ‡å®šè¶…å‚æ•°ç»„æˆçš„listå¯¹é»˜è®¤å€¼è¿›è¡Œè¦†ç›–
    cfg.freeze()	# å†»ç»“è¶…å‚æ•°ï¼Œé¿å…ç¨‹åºä¸å°å¿ƒä¿®æ”¹
    default_setup(cfg, args)	# engine/default.pyä¸­æä»çš„é»˜è®¤é…ç½®å‡½æ•°
    return cfg
```

è¿˜å®šä¹‰äº†`Trainer`ç±»ï¼Œç»§æ‰¿è‡ª`DefaultTrainer`ï¼Œä¼šè‡ªåŠ¨è§£æcfgï¼Œä¹‹åå€¼éœ€è¦è°ƒç”¨`trainer.train()`å°±å¯ä»¥å¼€å§‹è®­ç»ƒäº†

```python
'''mainå‡½æ•°'''

def main(args):
    cfg = setup(args)

    if args.eval_only:
        ...
    trainer = Trainer(cfg)
    trainer.resume_or_load(resume=args.resume)
    if cfg.TEST.AUG.ENABLED:
        trainer.register_hooks(
            [hooks.EvalHook(0, lambda: trainer.test_with_TTA(cfg, trainer.model))]
        )
    return trainer.train()
```

* plain_train_net

æ²¡æœ‰è°ƒç”¨é‚£ä¹ˆå¤šdefaultç±»åˆ«ï¼Œç”¨torchè‡ªå·±å†™çš„ã€‚(è‡ªç”±åˆ›å»ºè‡ªå·±çš„ä¼˜åŒ–å™¨,å¹¶ç¼–å†™è®­ç»ƒé€»è¾‘ï¼šä½¿ç”¨PyTorché€šå¸¸å¾ˆå®¹æ˜“,å¹¶ä¸”ä½¿ç ”ç©¶äººå‘˜å¯ä»¥çœ‹åˆ°æ•´ä¸ªè®­ç»ƒé€»è¾‘æ›´æ¸…æ™°å¹¶å…·æœ‰å®Œå…¨æ§åˆ¶æƒï¼Œæ”¯æŒç ”ç©¶è¿‡ç¨‹ä¸­å¯èƒ½æƒ³è¦çš„ä¸€äº›éæ ‡å‡†è¡Œä¸º)

* ä»–ä»¬éƒ½å¯ä»¥åœ¨å‘½ä»¤è¡Œç›´æ¥è®­ç»ƒï¼Œé€šå¸¸éœ€è¦è¾“å…¥configæ–‡ä»¶ï¼Œä¹Ÿå¯ä»¥æµ‹è¯•ï¼Œå‚æ•°æ˜¯` --eval-only`

## Setup Builtin Datasets

å„ç§å†…ç½®datasetçš„setupæ–‡ä»¶æ ‘æ ¼å¼ï¼Œä¾‹å¦‚ï¼šExpected dataset structure for COCO instance/keypoint detection

```
coco/
  annotations/
    instances_{train,val}2017.json
    person_keypoints_{train,val}2017.json
  {train,val}2017/
    # image files that are mentioned in the corresponding json
```

è¿™åº”è¯¥æ”¾åœ¨æŒ‡å®šçš„ç¯å¢ƒå˜é‡`DETECTRON2_DATASETS`ä¸­ï¼Œé»˜è®¤ä¸º`./dataset`ï¼Œå¯ä»¥é€šè¿‡`export DETECTRON2_DATASETS=/path/to/datasets`è®¾ç½®ã€‚

## Extend Detectron2â€™s Defaults

- è°ˆäº†è°ˆDetectron2çš„åŸºæœ¬è®¾è®¡æ€è·¯ã€‚ä¸€æ–¹é¢è¦æœ‰è¶³å¤Ÿçš„çµæ´»æ€§ï¼ˆåšç ”ç©¶æ€»æ˜¯è¦åšæ–°ä¸œè¥¿ï¼‰ï¼Œä¸€æ–¹é¢è¦æœ‰è¾ƒå¥½çš„é«˜å±‚æŠ½è±¡ï¼ˆç”¨æˆ·å¯ä»¥æ›´å¥½çš„æ“ä½œï¼‰ã€‚
- åŸºæœ¬è®¾è®¡æ€è·¯ï¼šæ‰€æœ‰çš„æ–¹æ³•å’Œç±»éƒ½å¯ä»¥ä»ä¸€ä¸ªé…ç½®æ–‡ä»¶ä¸­è·å–æ‰€éœ€è¦çš„å‚æ•°ï¼ˆé…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰çš„ï¼Œå°±ä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰ã€‚
- ä»‹ç»äº†æ‰©å±•detectron2çš„ä¸€äº›ç›¸å…³æ–‡æ¡£
  - ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†: [Use Custom Datasets](https://detectron2.readthedocs.io/tutorials/datasets.html).
  - è‡ªå®šä¹‰data loader from a datasetï¼š [Use Custom Data Loaders](https://detectron2.readthedocs.io/tutorials/data_loading.html).
  - ä½¿ç”¨æ ‡å‡†æ¨¡å‹å’Œé‡å†™å®ƒçš„æ¨¡å‹ï¼š[Use Models](https://detectron2.readthedocs.io/tutorials/models.html) and [Write Models](https://detectron2.readthedocs.io/tutorials/write-models.html).

  - ä½¿ç”¨hooksè‡ªå®šä¹‰training loopï¼š [training](https://detectron2.readthedocs.io/tutorials/training.html).

## Use Custom Datasets

ä½¿ç”¨äº† `detectron2/data/catalog.py`ä¸­çš„  `DatasetCatalog`å’Œ`MetadataCatalog`ã€‚

> In my opinion, `DatasetCatalog`å’Œ`MetadataCatalog`éƒ½æ˜¯Registerå¯¹è±¡ï¼ˆä¹‹åbuildinçš„dataloaderæ˜¯åŸºäºè¿™ä¸¤ä¸ªæ³¨å†Œå™¨å¯¹è±¡çš„ï¼‰ï¼Œè¿™ä¸€æ­¥çš„ç›®çš„å°±æ˜¯å°†è‡ªå®šä¹‰çš„æ•°æ®é›†æ³¨å†Œåˆ°`DatasetCatalog/MetadataCatalog._obj_map`ä¸­ã€‚
>
> å› æ­¤è¿™é‡Œè¿˜æ˜¯ä¿æŒregisterç±»çš„ä¸¤ä¸ªå±æ€§`_name`å’Œ`_obj_map`ï¼ˆç»„æˆå­—å…¸ï¼‰ï¼Œä¸¤ä¸ªæ–¹æ³•`register`å’Œ`get`(é€šè¿‡nameè·å¾—obj_map)
>
> è·å–å·²æ³¨å†Œçš„datasetï¼š`DatasetCatalog._REGISTERED`

1. **Register** your datasetï¼šå°†æ•°æ®é›†ä¿¡æ¯æ³¨å†Œåˆ°`DatasetCatalog`ï¼Œ`_obj_map`çš„valueä¸ºä¸€ä¸ª`get_dict`**æ–¹æ³•**ï¼Œè¯¥æ–¹æ³•ç”¨äºè·å–æ•°æ®é›†ï¼Œä¸ºä¸€ä¸ª `list[dict]` å¯¹è±¡ï¼Œæ¯ä¸ªå­—å…¸å°±æ˜¯ä¸€æ¡è¾“å…¥æ•°æ®ï¼š

   ```python
   def my_dataset_function():
     ...
     return list[dict] in the following format
   
   from detectron2.data import DatasetCatalog
   DatasetCatalog.register("my_dataset", my_dataset_function)
   ```

   å¯¹äºæ ‡å‡†ä»»åŠ¡ï¼Œè¯¥æ•°æ®é›†è¿˜éœ€è¦åœ¨ä¸‹æ¸¸æ­£ç¡®å¤„ç†ï¼Œå› æ­¤éœ€è¦æ ‡å‡†çš„æ³¨é‡Šè§„èŒƒï¼Œå…·ä½“çš„keyåˆ—è¡¨ï¼ˆæ•°æ®é›†çš„å±æ€§ï¼Œfile_nameï¼Œannotationsç­‰ï¼‰å¯ä»¥åˆ°æ–‡æ¡£ä¸­è‡ªå·±çœ‹[æ ‡å‡†æ•°æ®é›†å­—å…¸](https://detectron2.readthedocs.io/tutorials/datasets.html#standard-dataset-dicts)ï¼›

   å¯¹äºéœ€è¦é¢å¤–ä¿¡æ¯çš„æ–°ä»»åŠ¡ï¼Œä¹Ÿå¯ä»¥å­˜å‚¨ä»»æ„è‡ªå®šä¹‰çš„æ•°æ®ã€‚ä¸ºäº†ç¡®ä¿ä¸‹æ¸¸ä»£ç å¯ä»¥æ­£ç¡®å¤„ç†è¯¥æ•°æ®é›†ï¼Œéœ€è¦ä¸º`dataloader`é‡å†™ä¸€ä¸ªæ–°çš„`mapper`ã€‚

   ã€âš ï¸ã€‘æ¯ä¸ªå­—å…¸æ—¨åœ¨åŒ…å«æœ‰å…³æ¯ä¸ªæ ·æœ¬çš„å°‘é‡ä½†è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œä¾‹å¦‚file_nameå’Œannotations

2. é€‰æ‹©æ€§åœ°**register metadata** for your datasetï¼šã€å¯¹äºåœ¨æ•´ä¸ªæ•°æ®é›†ä¸­å…±äº«çš„å±æ€§ç§°ä¹‹ä¸ºå…ƒæ•°æ®ï¼Œå¦‚`names of classes, colors of classes, root of file`ç­‰ã€‘é€šè¿‡`MetadataCatalog.get(dataset_name).some_key = some_value`ï¼Œå°†è‡ªå®šä¹‰æ•°æ®é›†çš„**å…ƒæ•°æ®**æ³¨å†Œåˆ°`MetadataCatalog`ä¸­ï¼Œå†…ç½®çš„keyè§[æ•°æ®é›†å…ƒæ•°æ®](https://detectron2.readthedocs.io/tutorials/datasets.html#metadata-for-datasets)

---

* æ³¨å†Œcocoæ•°æ®é›†(cocoæ ¼å¼çš„jsonæ–‡ä»¶)

```python
from detectron2.data.datasets import register_coco_instances
register_coco_instances("my_dataset", {}, "json_annotation.json", "path/to/image/dir")
```

* **æ³¨å†Œäº†æ–°æ•°æ®é›†ä¹‹åï¼Œè¿˜éœ€è¦æ›´æ–°å¯¹åº”é…ç½®config**ï¼ˆå„ç§ç±»åˆ«æ•°ï¼‰

## Use Custom Dataloaders

`build_detection_{train,test}_loader`æ˜¯**é»˜è®¤çš„dataloader**ï¼š

1. ç”¨nameåŠ è½½æ•°æ®é›†çš„list[dict]
2. ç„¶åç”¨`mapper`å°†æ¯ä¸ªdictæ˜ å°„ä¸ºå¯ä¾›æ¨¡å‹ä½¿ç”¨çš„æ ¼å¼ï¼ˆåŒ…æ‹¬è¯»å›¾åƒï¼Œéšæœºæ•°æ®å¢å¼ºï¼Œè½¬åŒ–ä¸ºtorch Tensorsï¼‰ã€‚é»˜è®¤mapperæ˜¯`DatasetMaper`ï¼Œè¾“å‡ºæ ¼å¼ç¬¦åˆæ¨¡å‹è¦æ±‚çš„è¾“å…¥æ ¼å¼ã€‚
3. mapperçš„è¾“å‡ºè¢«batchedï¼ˆæ”¾è¿›ä¸€ä¸ªlistï¼‰
4. è¾“å‡ºã€‚é€šå¸¸ä½œä¸º`model.forward()`çš„è¾“å…¥

---

**è‡ªå®šä¹‰dataloader**

```python
from detectron2.data import build_detection_train_loader
from detectron2.data import transforms as T
from detectron2.data import detection_utils as utils

def mapper(dataset_dict):
	# Implement a mapper, similar to the default DatasetMapper, but with your own customizations
	dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below
  # è¯»å›¾åƒ
	image = utils.read_image(dataset_dict["file_name"], format="BGR")
  # è°ƒæ•´å›¾åƒä¸ºå›ºå®šå¤§å°
	image, transforms = T.apply_transform_gens([T.Resize((800, 800))], image)
  # è½¬tensor
	dataset_dict["image"] = torch.as_tensor(image.transpose(2, 0, 1).astype("float32"))
	
	annos = [
    # å¯¹å•ä¸ªinstanceçš„box/segmentation/keypointså®æ–½transforms
		utils.transform_instance_annotations(obj, transforms, image.shape[:2])
		for obj in dataset_dict.pop("annotations")
		if obj.get("iscrowd", 0) == 0
	]
  # åˆ›å»ºInstanceå®ä¾‹
	instances = utils.annotations_to_instances(annos, image.shape[:2])
  # æ»¤é™¤ç©ºçš„
	dataset_dict["instances"] = utils.filter_empty_instances(instances)
	return dataset_dict

# load
data_loader = build_detection_train_loader(cfg, mapper=mapper)
# use this dataloader instead of the default
```

* å¦‚æœæ˜¯ç”¨çš„DafaultTrainerï¼Œå¯ä»¥é‡å†™å®ƒçš„ `build_{train,test}_loader` ã€‚ä»¥denseposeçš„dataloaderä¸ºä¾‹
* å¦‚æœæ˜¯è‡ªå®šä¹‰å¾ªç¯ï¼Œå¯ä»¥è½»æ¾æ’å…¥dataloader

## Use Models

* å»ºç«‹æ¨¡å‹ï¼ˆè¿™é‡Œå»ºç«‹æ¨¡å‹ç»“æ„å¹¶éšæœºæ•°å¡«å……ï¼‰

```python
from detectron2.modeling import build_model
model = build_model(cfg)  # returns a torch.nn.Module
```

* è¯»å–/ä¿å­˜checkpoint

```python
from detectron2.checkpoint import DetectionCheckpointer
DetectionCheckpointer(model).load(file_path_or_url)  # load a file, usually from cfg.MODEL.WEIGHTS

checkpointer = DetectionCheckpointer(model, save_dir="output")
checkpointer.save("model_999")  # save to output/model_999.pth
```

* ä½¿ç”¨æ¨¡å‹`outputs = model(inputs)`, å…¶ä¸­input æ˜¯ list[dict]ï¼Œ[Inputæ ¼å¼](https://detectron2.readthedocs.io/tutorials/models.html#model-input-format)

â€”â€” è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œæ‰€æœ‰æ¨¡å‹éƒ½å¿…é¡»åœ¨EventStorageä¸­ä½¿ç”¨

```python
from detectron2.utils.events import EventStorage
with EventStorage() as storage:
  losses = model(inputs)
```

â€”â€” å¦‚æœè¦è¿›è¡Œæ¨ç†ï¼Œå¯ä»¥ç”¨`DefaultPredictor`ï¼Œæˆ–

```python
model.eval()
with torch.no_grad():
  outputs = model(inputs)
```

* å½“éœ€è¦ä¸­é—´å€¼æ—¶æœ‰ä¸¤ç§æ–¹æ³•

  1. ç¼–å†™å­æ¨¡å‹
  2. æ‰§è¡Œéƒ¨åˆ†æ¨¡å‹ï¼Œä¸ç”¨`forward()`ï¼Œè€Œæ˜¯è‡ªå®šä¹‰ä»£ç 


```python
images = ImageList.from_tensors(...)  # preprocessed input tensor
model = build_model(cfg)
# è‡ªå®šä¹‰ä¸€æ­¥ä¸€æ­¥åœ°æ‰§è¡Œ
features = model.backbone(images.tensor)
proposals, _ = model.proposal_generator(images, features)
instances = model.roi_heads._forward_box(features, proposals)
mask_features = [features[f] for f in model.roi_heads.in_features]
mask_features = model.roi_heads.mask_pooler(mask_features, [x.pred_boxes for x in instances])
```

## Write Models

ä»¥æ·»åŠ æ–°çš„backboneä¸ºä¾‹ï¼š

```python
from detectron2.modeling import BACKBONE_REGISTRY, Backbone, ShapeSpec

@BACKBONE_REGISTRY.register()
class ToyBackBone(Backbone):
  def __init__(self, cfg, input_shape):
    super().__init__()
    # create your own backbone
    self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=16, padding=3)

  def forward(self, image):
    return {"conv1": self.conv1(image)}

  def output_shape(self):
    return {"conv1": ShapeSpec(channels=64, stride=16)}
```

ç„¶ååœ¨configå¯¹è±¡overwrite`cfg.MODEL.BACKBONE.NAME = 'ToyBackBone'`ï¼Œä¹‹åçš„`build_model(cfg)`å°±æ˜¯`ToyBackBone`äº†

å†ä¸¾ä¸€ä¸ªä¾‹å­ï¼Œå¦‚æœè¦åœ¨generalized çš„RCNNä¸­æ·»åŠ ROI headï¼Œå¯ä»¥å®ç°ä¸€ä¸ªæ–°çš„ ROIHeadså¹¶å°†å…¶æ”¾åœ¨`ROI_HEADS_REGISTRY`ä¸­ã€‚å…·ä½“ç¤ºä¾‹è§projectçš„denseposeå’Œmeshrcnnã€‚

---

å®Œæ•´çš„æ³¨å†Œå™¨åˆ—è¡¨è§ [API documentation](https://detectron2.readthedocs.io/modules/modeling.html#model-registries)ï¼Œå¯ä»¥è‡ªå®šä¹‰éƒ¨åˆ†æˆ–å…¨éƒ¨æ¨¡å‹ã€‚

## Train

è§tools/{plain_}train_net.pyã€‚`TrainerBase`â¡`SimpleTrainer`â¡`DefaultTrainer`

* å¦‚æœè‡ªå®šä¹‰æ“ä½œä¸`DefaultTrainer`ç›¸ä¼¼ï¼Œåˆ™ç»§æ‰¿`DefaultTrainer`ï¼Œå¦‚train_net.py
* å¦‚æœéœ€è¦å…¶ä»–ä¸œè¥¿ï¼Œåˆ™å‚è€ƒplain_train_net.pyå®ç°

è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ‰€æœ‰çš„metricséƒ½ä¿å­˜åœ¨eventstorageä¸­ã€‚EventWriter å¯ä»¥å°†metricså†™å…¥ç›®æ ‡ä½ç½®

```python
from detectron2.utils.events import get_event_storage

# inside the model:
if self.training:
  value = # compute the value from inputs
  storage = get_event_storage()
  storage.put_scalar("some_accuracy", value)
  
  
# æˆ–
from detectron2.utils.events import EventStorage
with EventStorage() as storage:
  losses = model(inputs)
```

## Evaluation

è¯„ä»·è¿‡ç¨‹éœ€è¦å¯¹è¾“å…¥è¾“å‡ºè¿›è¡ŒåŒ¹é…å’Œæ±‡æ€»ã€‚

* å¯ä»¥ç›´æ¥ [use the model](https://detectron2.readthedocs.io/tutorials/models.html) ï¼Œç„¶åæ‰‹åŠ¨çš„æ‰§è¡Œè¯„ä»·ã€‚

```python
def get_all_inputs_outputs():
  for data in data_loader:
    yield data, model(data)

evaluator.reset()
for inputs, outputs in get_all_inputs_outputs():
  evaluator.process(inputs, outputs)
eval_results = evaluator.evaluate()
```

* ä¹Ÿå¯ä»¥ä½¿ç”¨`DatasetEvaluator`ã€‚`DatasetEvaluator`æœ‰ä¸€äº›é’ˆå¯¹æ ‡å‡†æ•°æ®é›†è®¡ç®—metricsçš„å­ç±»ã€‚ä¹Ÿå¯ä»¥è‡ªå®šä¹‰å…¶ä»–åŠŸèƒ½ï¼Œå¦‚è®¡ç®—æœ‰å‡ ä¸ªå®ä¾‹ï¼š

```python
class Counter(DatasetEvaluator):
  def reset(self):
    self.count = 0
  def process(self, inputs, outputs):
    for output in outputs:
      self.count += len(output["instances"])
  def evaluate(self):
    # save self.count somewhere, or print it, or return it.
    return {"count": self.count}
```

* è¿˜å¯ä»¥å’Œinference_on_datasetä¸€èµ·ä½¿ç”¨

```python
# åœ¨data_loaderä¸Šæ‰§è¡Œmodelï¼Œå¹¶ç”¨evaluatorè¯„ä¼°metricsã€‚modelå°†ä»¥eval modeæ‰§è¡Œï¼Œè¿”å›evaluator.evaluate()
eval_results = inference_on_dataset(
    model,
    data_loader,
    DatasetEvaluators([COCOEvaluator(...), Counter()]))
```

## Configs

- [x] æ²¡ä»€ä¹ˆé—®é¢˜

ã€âš ï¸ã€‘

1. é¿å…configé‡å¤ï¼Œç”¨`__BASE__`æ¥å…±äº«é…ç½®ä¹‹é—´çš„å…¬å…±éƒ¨åˆ†
2. configä¿æŒç®€æ´ï¼Œä¸è¦åŒ…å«ä¸å½±å“å®éªŒçš„é…ç½®
3. å†™configæ—¶ï¼Œä¿ç•™ç‰ˆæœ¬å·å¦‚`VERSION: 2`ï¼Œä»¥å…ä¸å…¼å®¹

# Colab Notebook

## **Install detectron2**

é‡Œé¢æœ‰ä¸€æ®µæµ‹è¯•

```python
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import cv2
import random
# from google.colab.patches import cv2_imshow

# import some common detectron2 utilities
from detectron2 import model_zoo	# æ¨¡å‹åº“
from detectron2.engine import DefaultPredictor	# é¢„æµ‹å™¨
from detectron2.config import get_cfg	# é…ç½®
from detectron2.utils.visualizer import Visualizer	# å¯è§†åŒ–
from detectron2.data import MetadataCatalog	# è‡ªå®šä¹‰datasetç”¨çš„
```

## **Run a pre-trained detectron2 model**

- [x] demo-related
```python
# åˆ›å»ºé…ç½®ï¼ˆç±»ä¼¼ä¸argparseå®ä¾‹åŒ–ä¸€ä¸ªå¯¹è±¡ï¼‰
cfg = get_cfg()
# æ·»åŠ é…ç½®ï¼ˆfrom fileï¼Œfrom listå’Œç›´æ¥æ·»åŠ ï¼‰
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model
cfg.MODEL.DEVICES = 'cpu'

# ä»model zooä¸­é€‰åœ¨ä¸€ä¸ªé¢„è®­ç»ƒçš„modelåŠå…¶é…ç½®æ–‡ä»¶ï¼Œä¼šè¿”å›ä¸€ä¸ªurl
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")

# åˆ›å»ºé»˜è®¤é¢„æµ‹å™¨
predictor = DefaultPredictor(cfg)	# åœ¨engineé‡Œé¢
outputs = predictor(im)

# outputs['instances']åŒ…å«äº†æ¯ä¸ªinstanceçš„ç±»å‹, box, maskç­‰ä¿¡æ¯
print(outputs["instances"].pred_classes)
print(outputs["instances"].pred_boxes)

# å¯è§†åŒ–ï¼Œï¼ˆimg_rgb, å…ƒæ•°æ®ï¼‰ï¼Œ[:, :, ::-1]æŠŠrgbé¡ºåºå€’ä¸€è½¬ï¼Œå› ä¸ºcv2æ˜¯bgrçš„
v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
# åœ¨å›¾åƒä¸Šç»˜åˆ¶å®ä¾‹çº§é¢„æµ‹ç»“æœã€‚
v = v.draw_instance_predictions(outputs["instances"].to("cpu"))	
cv2_imshow(v.get_image()[:, :, ::-1])
```

## Train on a custom dataset

ä»cocoä¸è®­ç»ƒæ¨¡å‹ä¸è®­ç»ƒballoonåˆ†å‰²æ¨¡å‹

### ï¼ˆä¸€ï¼‰prepare the dataset

```python
# å¦‚æœæ˜¯cocoæ ¼å¼çš„æ•°æ®é›†ï¼Œå¯ä»¥ç”¨ä»¥ä¸‹ä¸‰è¡Œä»£æ›¿ï¼ˆcocoæ ¼å¼è§buildin datasetï¼‰
# from detectron2.data.datasets import register_coco_instances
# register_coco_instances("my_dataset_train", {}, "json_annotation_train.json", "path/to/image/dir")
# register_coco_instances("my_dataset_val", {}, "json_annotation_val.json", "path/to/image/dir")

import os
import numpy as np
import json
from detectron2.structures import BoxMode

'''è§£æè‡ªå®šä¹‰æ•°æ®ï¼ˆjsonæ ¼å¼çš„lable)'''
def get_balloon_dicts(img_dir):
    json_file = os.path.join(img_dir, "via_region_data.json")
    with open(json_file) as f:
        imgs_anns = json.load(f)

    dataset_dicts = []
    for idx, v in enumerate(imgs_anns.values()):
        record = {}
        
        filename = os.path.join(img_dir, v["filename"])
        height, width = cv2.imread(filename).shape[:2]
        
        record["file_name"] = filename
        record["image_id"] = idx
        record["height"] = height
        record["width"] = width
      
        annos = v["regions"]
        objs = []
        for _, anno in annos.items():
            assert not anno["region_attributes"]
            anno = anno["shape_attributes"]
            px = anno["all_points_x"]
            py = anno["all_points_y"]
            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]
            poly = [p for x in poly for p in x]

            obj = {
                "bbox": [np.min(px), np.min(py), np.max(px), np.max(py)],
                "bbox_mode": BoxMode.XYXY_ABS,
                "segmentation": [poly],
                "category_id": 0,
            }
            objs.append(obj)
        record["annotations"] = objs
        dataset_dicts.append(record)
    return dataset_dicts

from detectron2.data import DatasetCatalog, MetadataCatalog	# ./detectron2/data/catalog.py

# æ³¨å†Œè®­ç»ƒå’ŒéªŒè¯æ•°æ®çš„æ•°æ®é›†å’Œå…ƒæ•°æ®
for d in ["train", "val"]:
  	# train/valæ•°æ®æ³¨å†Œåˆ°DatasetCatalogä¸­ï¼Œä¿å­˜ä¸€ä¸ªå­—å…¸{balloon_train/val:è·å¾—æ•°æ®çš„æ–¹æ³•}
    DatasetCatalog.register("balloon_" + d, lambda d=d: get_balloon_dicts("balloon/" + d))
    # å°†æ–°æ•°æ®çš„å…ƒæ•°æ®æ³¨å†Œåˆ°MetadataCatalogä¸­ï¼šä¸ºæ–°æ•°æ®æ·»åŠ å…ƒæ•°æ®ï¼Œå¹¶å®šä¹‰æˆ‘ä»¬è¦åˆ°çš„ç±»åˆ«
    MetadataCatalog.get("balloon_" + d).set(thing_classes=["balloon"])
    
# è®¿é—®ballon_trainçš„å…ƒæ•°æ®ã€‚ï¼ˆregisterå¯¹è±¡.getå¯ä»¥ç›´æ¥è°ƒç”¨å®šä¹‰çš„ç±»ï¼‰ -> ç”¨äºvisualize
balloon_metadata = MetadataCatalog.get("balloon_train")
```

### ï¼ˆäºŒï¼‰Train

```python
from detectron2.engine import DefaultTrainer	# engineé‡Œä¸»è®­ç»ƒè¯„ä¼°
from detectron2.config import get_cfg					# configé‡Œä¸»é…ç½®

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("balloon_train",)
cfg.DATASETS.TEST = ()
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")  # Let training initialize from model zoo
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR
cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg) 
trainer.resume_or_load(resume=False)
trainer.train()
```

+ ç”¨tensorboardçœ‹training curves

### ï¼ˆä¸‰ï¼‰Inference & evaluation

```python
cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model
cfg.DATASETS.TEST = ("balloon_val", )
predictor = DefaultPredictor(cfg)

# éšæœºé€‰æ‹©å‡ ä¸ªæ ·æœ¬æ¥å¯è§†åŒ–é¢„æµ‹ç»“æœ
from detectron2.utils.visualizer import ColorMode
dataset_dicts = get_balloon_dicts("balloon/val")
for d in random.sample(dataset_dicts, 3):    
    im = cv2.imread(d["file_name"])
    # é¢„æµ‹
    outputs = predictor(im)
    # å¯è§†åŒ–
    v = Visualizer(im[:, :, ::-1],
                   metadata=balloon_metadata, 
                   scale=0.8, 
                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels
    )
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(out.get_image()[:, :, ::-1])
    
# ç”¨AP metricæŒ‡æ ‡è¯„ä¼°å…¶æ€§èƒ½ï¼ˆaverage precisionå’Œaverage Recallï¼‰
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader
# evaluator
evaluator = COCOEvaluator("balloon_val", cfg, False, output_dir="./output/")
# evaldataset
val_loader = build_detection_test_loader(cfg, "balloon_val")
# eval
inference_on_dataset(trainer.model, val_loader, evaluator)
# another equivalent way is to use trainer.testï¼›åŒæ ·å¯ä»¥ä½¿ç”¨trainer.test
```

## Other types of builtin models

åŒ…æ‹¬å…³é”®ç‚¹ï¼Œå…¨æ™¯åˆ†å‰²å’Œå…¨æ™¯åˆ†å‰²on videoã€‚

# æºç ç†è§£

> **ä»£ç é€»è¾‘åˆ†æ**ï¼šdetectron2å°†æ¨¡å‹æ‹†åˆ†ä¸ºå¤šä¸ªæ¨¡å—ï¼Œé€šè¿‡é…ç½®æ–‡ä»¶æ¥é€‰æ‹©å¯¹åº”çš„æ¨¡å—æ­å»ºæ¨¡å‹ã€‚

## ï¼ˆä¸€ï¼‰Config&Trainer

`Detectron2`çš„å¤§è‡´é€»è¾‘ï¼š

1. **è¶…å‚æ•°é…ç½®**

ä½¿ç”¨`yacs`åº“ï¼Œèƒ½å¤Ÿå¾ˆå¥½åœ°é‡ç”¨å’Œæ‹¼æ¥è¶…å‚æ•°æ–‡ä»¶é…ç½®ã€‚

- é»˜è®¤é…ç½®æ–‡ä»¶ï¼š `./detectron2/config/defaults.py` 
- å®ä¾‹é…ç½®æ–‡ä»¶ï¼š `./configs`æ–‡ä»¶å¤¹ä¸­ï¼Œyamlæ ¼å¼ï¼ˆå®ä¾‹é…ç½®åœ¨é»˜è®¤é…ç½®çš„åŸºç¡€ä¸Šï¼Œç»§æ‰¿`_BASE_`å±æ€§åªæƒ³çš„å®ä¾‹æ–‡ä»¶ï¼Œå†²çªä½¿ç”¨å½“å‰ï¼‰

2. **Trainer**

`./tools`é‡Œæœ‰ä¸¤ä¸ªæ–‡ä»¶ï¼š

* `train_net.py`é‡Œå®šä¹‰äº†ä¸€ä¸ªç»§æ‰¿è‡ª`./detectron2.engine.default.DefaultTrainer`çš„Trainerï¼Œè¿™ä¸ªçˆ¶ç±»ä¼šè‡ªåŠ¨è§£æcfgï¼Œä¹‹åè°ƒç”¨`trainer.train()`å°±å¯ä»¥å¼€å§‹è®­ç»ƒäº†ã€‚
* `plain_train_net.py`åˆ™æ›´å¤šçš„è‡ªå®šä¹‰æ¨¡å‹ï¼Œä¼˜åŒ–å‡½æ•°ç­‰

## ï¼ˆäºŒï¼‰Registry&build_*æ–¹æ³•

è¦äº†è§£`DefaultTrainer`æ˜¯å¦‚ä½•è§£æcfgçš„ï¼Œéœ€è¦äº†è§£`detectron2`çš„`Registry`æœºåˆ¶ï¼Œå’Œ`DefaultTrainer`ç±»ä¸­çš„å„ç§`build_*`å‡½æ•°

1. **build_*æ–¹æ³•**

åœ¨`DefaultTrainer`çš„`__init__(self, cfg)`å‡½æ•°ä¸­ï¼Œå®šä¹‰äº†è‹¥å¹²ä¸ª`build_*`æ–¹æ³•ï¼Œè§£æcfgï¼Œå¾—åˆ°è§£æåçš„model,optimizer,data_loaderç­‰ã€‚ä¸‹é¢ä»¥`build_model`ä¸ºä¾‹ï¼š

è¯¥æ–¹æ³•è°ƒç”¨äº†`detectron2/modeling/meta_arch/build_model.py`çš„`build_model`å‡½æ•°ï¼Œæºä»£ç å¦‚ä¸‹ï¼š

```python
from detectron2.utils.registry import Registry

META_ARCH_REGISTRY = Registry("META_ARCH")  # noqa F401 isort:skip
META_ARCH_REGISTRY.__doc__ = """
Registry for meta-architectures, i.e. the whole model.

The registered object will be called with `obj(cfg)`
and expected to return a `nn.Module` object.
"""


def build_model(cfg):
    """
    Build the whole model architecture, defined by ``cfg.MODEL.META_ARCHITECTURE``.
    Note that it does not load any weights from ``cfg``.
    """
    meta_arch = cfg.MODEL.META_ARCHITECTURE	# æ ¹æ®è¶…å‚æ•°è·å¾—ç½‘ç»œç»“æ„çš„åå­—
    model = META_ARCH_REGISTRY.get(meta_arch)(cfg)	# å…¶ä¸­META_ARCH_REGISTRYæ˜¯ä¸€ä¸ªRegisterç±»
    model.to(torch.device(cfg.MODEL.DEVICE))
    return model
```

2. **Registryæœºåˆ¶**

`Registry`æºä»£ç å¦‚ä¸‹ï¼ˆæœ‰åˆ å‡ï¼‰ï¼Œæ¥è‡ªäº`fvcore.common.registry.Registry`ï¼š

```Python
class Registry(object):
    def __init__(self, name):
        self._name = name
        self._obj_map = {}

    def _do_register(self, name, obj):
        assert (
            name not in self._obj_map
        ), "An object named '{}' was already registered in '{}' registry!".format(name, self._name)
        self._obj_map[name] = obj

    def register(self, obj=None):
        if obj is None:
            # used as a decorator
            def deco(func_or_class):
                name = func_or_class.__name__
                self._do_register(name, func_or_class)
                return func_or_class

            return deco

        # used as a function call
        name = obj.__name__
        self._do_register(name, obj)

    def get(self, name):
        ret = self._obj_map.get(name)
        if ret is None:
            raise KeyError("No object named '{}' found in '{}' registry!".format(name, self._name))
        return ret
```

* **ä¸¤ä¸ªå±æ€§**ï¼š

  * `self._name`æ˜¯è¦æ³¨å†Œçš„**åå­—**ï¼Œå¯¹äºå®Œæ•´æ¨¡å‹ï¼Œnameä¸ºMETA_ARCHï¼Œå¯¹äºbackboneï¼Œnameä¸ºBACKBONEï¼›
  * `self._obj_map`æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œ**keyä¸ºæ¨¡å‹åå­—(*ä¸æ˜¯å¯¹è±¡çš„åå­—*)ï¼Œvalueä¸ºå¯¹åº”çš„æ¨¡å‹**ã€‚

* **ä¸¤ä¸ªæ–¹æ³•**ï¼ˆ`register`å’Œ`get`ï¼Œå…¶ä¸­`register`è°ƒç”¨`_do_register`ï¼‰ï¼š

  * `register`ï¼šå®šä¹‰äº†å¦‚ä¸Šä¸¤ç§æ³¨å†Œæ–¹å¼ï¼Œ1) å¯¹è±¡ä¸å­˜åœ¨`obj==None`ï¼Œä½¿ç”¨è£…é¥°å™¨`@registry_object.register`ä¿®é¥°ï¼›2) å¯¹è±¡å­˜åœ¨ï¼Œç›´æ¥è°ƒç”¨`_do_register`ã€‚**å› æ­¤`_do_register`æ˜¯çœŸæ­£çš„æ³¨å†Œå‡½æ•°ã€‚**å®ƒä¼šå…ˆåˆ¤æ–­`name`æ˜¯å¦å·²å­˜åœ¨äº`_obj_map`ï¼Œæ²¡æœ‰çš„è¯ï¼Œå°±æŠŠè¿™ä¸ªnameåŠ åˆ°`_obj_map`è¿™ä¸ªdictä¸­ã€‚

    > è¿˜æ˜¯ä»¥backboneä¸ºä¾‹ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ª`BACKBONE_REGISTRY = Registry('BACKBONE')`,ç„¶ååˆå®šä¹‰äº†å¾ˆå¤šç§backboneï¼Œè€Œè¿™äº›backboneéƒ½ä½¿ç”¨`@BACKBONE_REGISTRY.register()`çš„æ–¹å¼æ³¨å†Œåˆ°äº†`BACKBONE_REGISTRY._obj_map`ä¸­

  * `get`ï¼šå¯ä»¥é€šè¿‡`å¯¹è±¡.get(æ–¹æ³•)`çš„åŠæ³•æ¥é—´æ¥çš„è°ƒç”¨è¢«æ³¨å†Œçš„å‡½æ•°ï¼Œå…¶å®å°±æ˜¯æ ¹æ®keyå–å€¼valueã€‚

è¿™æ ·ï¼Œå¯ä»¥æ–¹ä¾¿çš„æ ¹æ®é…ç½®æ–‡ä»¶ï¼Œä¼ å‚æ—¶ä¸åŒçš„åå­—å°±èƒ½ç›´æ¥åˆ›å»ºå¯¹åº”çš„å¯¹è±¡ã€‚

---

**åœ¨detectron2ä¸­**

- æ¯ä¸ªç±»å‹çš„modelingéƒ½åŒ…å«ä¸€ä¸ªRegistryå¯¹è±¡ã€‚å¦‚backbone, anchor generator, proposal generator, roi headç­‰ï¼Œè§ `detectron2/modeling/` ã€‚
- å¤§çš„Registryï¼ˆç”±ä¸€ä¸ªåŒ…ç»„æˆï¼‰å¯¹åº”ä¸€ä¸ª**build.py**ï¼Œæ ¹æ®`*_REGISTRY._obj_map`è¿™ä¸ªdictï¼Œé€šè¿‡nameè·å–å¯¹åº”æ¨¡å‹ï¼Œç„¶åå°†ç¤ºä¾‹é…ç½®æ–‡ä»¶ä¸­å‚æ•°å¯¼å…¥ç›®æ ‡æ¨¡å‹ä¸­ã€‚

> ä»¥å®ç°æ–°çš„backboneç½‘ç»œä¸ºä¾‹ï¼š
>
> 1ï¼‰ é¦–å…ˆå®šä¹‰ä¸€ä¸ªåå­—ä¸ºbackboneçš„registerç±»ï¼ˆdetectron2è‡ªå¸¦ï¼‰
>
> ```python
> # detectron2/modeling/backbone/build.py
> BACKBONE_REGISTRY = Registry('BACKBONE')
> ```
>
> 2) ç„¶ååœ¨åˆ›å»ºçš„æ–°æ–‡ä»¶ä¸‹ï¼Œä»¥å¦‚ä¸‹æ–¹å¼åˆ›å»ºè‡ªå®šä¹‰çš„backboneï¼ˆdetectron2ä¸­è‡ªå¸¦fpnå’Œresnetï¼Œresnetæ¯”è¾ƒå®Œæ•´ã€**å¯å‚è€ƒ**ã€‘ï¼‰
>
> ```python
> # detectron2/modeling/backbone/your_backbone.py
> from .build import BACKBONE_REGISTRY
> 
> # æ–¹å¼1
> @BACKBONE_REGISTRY.register()
> class MyBackbone():
> 	...
> 		
> # æ–¹å¼2
> class MyBackbone():!
> 	...
> BACKBONE_REGISTRY.register(MyBackbone)
> ```

## ï¼ˆä¸‰ï¼‰Dataset pipeline

æ„å»ºdata_loaderçš„ä¸¤ä¸ªé‡è¦å‡½æ•°`build_detection_{train/test}_loader`åœ¨`./data/build.py`ï¼Œå®ƒä»¬çš„è¾“å‡ºæ˜¯modelçš„è¾“å…¥ã€‚ä»¥`build_detection_train_loader`ä¸ºä¾‹

```python
def build_detection_train_loader(cfg, mapper=None):
    """
    A data loader is created by the following steps:

    1. Use the dataset names in config to query :class:`DatasetCatalog`, and obtain a list of dicts.
    2. Start workers to work on the dicts. Each worker will:
      * Map each metadata dict into another format to be consumed by the model.
      * Batch them by simply putting dicts into a list.
    The batched ``list[mapped_dict]`` is what this dataloader will return.

    Args:
        cfg (CfgNode): the config
        mapper (callable): a callable which takes a sample (dict) from dataset and
            returns the format to be consumed by the model.
            By default it will be `DatasetMapper(cfg, True)`.

    Returns:
        a torch DataLoader object
    """
	# è·å¾—dataset_dicts
    dataset_dicts = get_detection_dataset_dicts(
        cfg.DATASETS.TRAIN,
        filter_empty=True,
        min_keypoints=cfg.MODEL.ROI_KEYPOINT_HEAD.MIN_KEYPOINTS_PER_IMAGE
        if cfg.MODEL.KEYPOINT_ON
        else 0,
        proposal_files=cfg.DATASETS.PROPOSAL_FILES_TRAIN if cfg.MODEL.LOAD_PROPOSALS else None,
    )
	
	# å°†dataset_dictsè½¬åŒ–æˆtorch.utils.data.Dataset
    dataset = DatasetFromList(dataset_dicts, copy=False)

	# è¿›ä¸€æ­¥è½¬åŒ–æˆMapDatasetï¼Œæ¯æ¬¡è¯»å–æ•°æ®æ—¶éƒ½ä¼šè°ƒç”¨mapperæ¥å¯¹dictè¿›è¡Œè§£æ
    if mapper is None:
        mapper = DatasetMapper(cfg, True)
    dataset = MapDataset(dataset, mapper)
	
	# é‡‡æ ·å™¨
    sampler_name = cfg.DATALOADER.SAMPLER_TRAIN
    if sampler_name == "TrainingSampler":
        sampler = samplers.TrainingSampler(len(dataset))
		...
    batch_sampler = build_batch_data_sampler(
        sampler, images_per_worker, group_bin_edges, aspect_ratios
    )
	
	# æ•°æ®è¿­ä»£å™¨ data_loader
    data_loader = torch.utils.data.DataLoader(
        dataset,
        num_workers=cfg.DATALOADER.NUM_WORKERS,
        batch_sampler=batch_sampler,
        collate_fn=trivial_batch_collator,
        worker_init_fn=worker_init_reset_seed,
    )
    return data_loader
ç”±æºä»£ç å¯çŸ¥ï¼Œæ„å»ºdataloaderå…±äº”ä¸ªæ­¥éª¤ï¼š
```
* ç¬¬ä¸€æ­¥ï¼Œè·å¾—dataset_dictsã€‚æ ¹æ®dataset_namesï¼Œè°ƒç”¨`DatasetCatalog`æ¥è¿›è¡Œè§£æå¾—åˆ°ä¸€ä¸ªåŒ…å«æ•°æ®ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨ - list[dict]ã€‚

  ```python
  from detectron2.data import DatasetCatalog
  my_dataset_name = 'apple'
  def get_dicts():
  	...
  	return dict
  
  DatasetCatalog.register(my_dataset_name, get_dicts)
  DatasetCatalog.get()	# è¿”å›åˆšåˆšæ³¨å†Œçš„get dictå‡½æ•°
  ```

  å¦‚æœæ•°æ®é›†å·²ç»æ˜¯cocoæ ¼å¼ï¼Œé‚£ä¹ˆç”¨å¦‚ä¸‹æ–¹æ³•æ³¨å†Œï¼š

  ```python
  from detectron2.data.datasets import register_coco_instances
  my_dataset_name = 'apple'
  register_coco_instances(my_dataset_name, {}, "json_annotation.json", "path/to/image/dir")
  ```

  æ•°æ®é›†ç”±ä¸¤ä¸ªç±»å®šä¹‰ï¼Œé™¤äº†`datasetcatalog`ï¼Œè¿˜æœ‰`MetadataCatalog`è®°å½•å…ƒæ•°æ®ã€‚

  åœ¨æ³¨å†Œ`datasetcatalog`åï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å¯¹`metadatacatalog`è¿›è¡Œæ³¨å†Œï¼Œå®šä¹‰æˆ‘ä»¬å¯èƒ½ç”¨åˆ°çš„å±æ€§ç‰¹å¾ï¼š

  ```python
  from detectron2.data import MetadataCatalog
  MetadataCatalog.get("my_dataset").thing_classes = ["person", "dog"]
  
  # ä¹Ÿå¯ä»¥è¿™æ ·
  MetadataCatalog.get("my_dataset").set("thing_classes",["person", "dog"])
  ```

* ç¬¬äºŒæ­¥ï¼Œå°†dataset_dictsè½¬åŒ–æˆ`torch.utils.data.Dataset`ã€‚åœ¨`detectron2/data/common.py`ä¸­ï¼Œç»§æ‰¿äº`torch.utils.data.Dataset`ã€‚è½¬æ¢ä¹‹åæ”¯æŒç´¢å¼•(dataset[i]è¯»å•ä¸ªæ•°æ®)

  ```python
  class DatasetFromList(data.Dataset):
      """
      Wrap a list to a torch Dataset. It produces elements of the list as data.
      """
  
      def __init__(self, lst: list, copy: bool = True):
          """
          Args:
              lst (list): a list which contains elements to produce.
              copy (bool): whether to deepcopy the element when producing it,
                  so that the result can be modified in place without affecting the
                  source in the list.
          """
          self._lst = lst
          self._copy = copy
  
      def __len__(self):
          return len(self._lst)
  
      def __getitem__(self, idx):
          if self._copy:
              return copy.deepcopy(self._lst[idx])
          else:
              return self._lst[idx]
  ```

* ç¬¬ä¸‰æ­¥ï¼Œè¿›ä¸€æ­¥è½¬åŒ–æˆMapDatasetï¼Œæ¯æ¬¡è¯»å–æ•°æ®æ—¶éƒ½ä¼šè°ƒç”¨mapperæ¥å¯¹dictè¿›è¡Œè§£æï¼Œå°†æ¯ä¸ªdictæ˜ å°„ä¸ºå¯ä¾›æ¨¡å‹ä½¿ç”¨çš„æ ¼å¼ï¼Œä¸»è¦å·¥ä½œåŒ…æ‹¬è¯»å–å›¾åƒã€resizeã€cropã€flipã€è½¬æ¢æ•°æ®ä¸æ ‡ç­¾çš„å½¢å¼ç­‰ã€‚

  é»˜è®¤çš„mapperä¸ºDatasetMapperï¼Œæºç å¦‚ä¸‹ï¼ˆæœ‰åˆ å‡ï¼‰

  ```python
  class DatasetMapper:
      def __init__(self, cfg, is_train=True):
  		# è¯»å–cfgçš„å‚æ•°
  		...
  
      def __call__(self, dataset_dict):
          """
          Args:
              dataset_dict (dict): Metadata of one image, in Detectron2 Dataset format.
  
          Returns:
              dict: a format that builtin models in detectron2 accept
          """
          dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below
  		
  		# 1. è¯»å–å›¾åƒæ•°æ®
          image = utils.read_image(dataset_dict["file_name"], format=self.img_format)
  		
  		# 2. å¯¹imageå’Œboxç­‰åšTransformation
          if "annotations" not in dataset_dict:
              image, transforms = T.apply_transform_gens(
                  ([self.crop_gen] if self.crop_gen else []) + self.tfm_gens, image
              )
          else:
  			...
              image, transforms = T.apply_transform_gens(self.tfm_gens, image)
              if self.crop_gen:
                  transforms = crop_tfm + transforms
  ```

  `MapDataset`è¿˜æ˜¯ç»§æ‰¿è‡ª`data.Dataset`ï¼Œè°ƒç”¨mapperï¼ˆmap_funcï¼‰æ¥è½¬æ¢æ•°æ®ï¼ˆè¿”å›è¿˜æ˜¯Datasetï¼‰

  ```python
  class MapDataset(data.Dataset):
      def __init__(self, dataset, map_func):
          self._dataset = dataset
          self._map_func = PicklableWrapper(map_func)  # wrap so that a lambda will work
  
          self._rng = random.Random(42)
          self._fallback_candidates = set(range(len(dataset)))	# è¿™ä¸ªsetå¯ä»¥å®ç°å»é‡
  
      def __len__(self):
          return len(self._dataset)
  
      def __getitem__(self, idx):
      '''
      __getitem__å’Œself._fallback_candidatesé…åˆï¼Œå°†èƒ½å¤Ÿæ­£å¸¸é€šè¿‡map_funcçš„æ•°æ®åŠ å…¥åˆ°_fallback_candidatesä¸­å»ï¼Œå¦åˆ™ä¸¢å¼ƒã€‚
      '''
          retry_count = 0
          cur_idx = int(idx)
  
          while True:
              data = self._map_func(self._dataset[cur_idx])
              if data is not None:
                  self._fallback_candidates.add(cur_idx)
                  return data
  
              # _map_func fails for this idx, use a random new index from the pool
              retry_count += 1
              self._fallback_candidates.discard(cur_idx)
              cur_idx = self._rng.sample(self._fallback_candidates, k=1)[0]
  
              if retry_count >= 3:
                  logger = logging.getLogger(__name__)
                  logger.warning(
                      "Failed to apply `_map_func` for idx: {}, retry count: {}".format(
                          idx, retry_count
                      )
                  )
  ```

* ç¬¬å››æ­¥ï¼Œç”Ÿæˆé‡‡æ ·å™¨ã€‚æ„å»º`torch.utils.data.sampler.Sampler`å¯¹è±¡ï¼ŒåŒ…æ‹¬Repeat Sampleã€shuffleã€batchåŠŸèƒ½ã€‚

* ç¬¬äº”æ­¥ï¼Œç”Ÿæˆæ•°æ®è¿­ä»£å™¨data_loaderã€‚

# æºç é˜…è¯»ç¬”è®°

## æ•°æ®å¤„ç†

<img src="https://i.loli.net/2020/06/17/Y7mPbOdVIkT2DyM.png" alt="image-20200617101826563" style="zoom:50%;" />

* å®ç°åŠŸèƒ½ï¼šé€šè¿‡é…ç½®æ–‡ä»¶å³å¯å®ç°æ•°æ®é›†è§£æã€é¢„å¤„ç†ã€å¢å¼ºç­‰æ“ä½œã€‚
* ç›¸å…³ä»£ç ï¼šä¸»è¦ä½äº `detectron2/detectron2/data` ç›®å½•ä¸‹ã€‚
* ä¸»è¦å…¥å£ï¼š `detectron2/data/build.py` ä¸­çš„ `build_detection_{train/test}_loader`æ–¹æ³•ã€‚
* ç›¸å…³é…ç½®ï¼š`detectron2/config/defaults.py` ä¸­ `_C.INPUT _C.DATASETS _C.DATALOADER` å¼€å¤´çš„é…ç½®ã€‚

ã€å…¶ä»–ã€‘

* æ•°æ®å¢å¼ºï¼Œä¸»è¦åœ¨`detectron2/detectron2/data/transforms/transform_gen.py` ä¸­å®šä¹‰ï¼Œè°ƒç”¨ä¸»è¦æ˜¯é€šè¿‡ `from detectron2.data import transforms as T` ç„¶å `T.ResizeShortestEdge` æ¥å®ç°ã€‚

---

**åŸºæœ¬æµç¨‹**ï¼šè§[build_detection_train_loader](##ï¼ˆä¸‰ï¼‰Dataset pipeline)

1. æ³¨å†Œæ•°æ®é›†ï¼ˆåŒ…æ‹¬datasetå’Œmetadataï¼‰ï¼š`DatasetCatalog.register(dataset_name, get_dict_func)`&`MetadataCatalog.get(dataset_name).set(name, value)`ã€‚

   > `detectron2`ä¸­æœ‰æ³¨å†Œä¸€äº›å¸¸ç”¨æ•°æ®é›†ï¼Œåœ¨`detectron2/detectron2/data/datasets/builtin.py`ä¸­

2. é€šè¿‡`dataset name`å’Œ`DatasetCatalog`ï¼Œè·å¾— a list of dictsã€‚

   > é»˜è®¤çš„æ–¹æ³•æ˜¯build.pyä¸­çš„get_detection_dataset_dicts

3. é€šè¿‡`mapper`è½¬æ¢æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š

   * å°†åŸå§‹æ•°æ®è½¬åŒ–ä¸ºå¯ä¾›æ¨¡å‹ä½¿ç”¨çš„æ•°æ®æ ¼å¼ï¼ˆDatasetï¼‰

   * å„ç§é¢„å¤„ç†

4. batch them & ç”Ÿæˆdataloader

## æ¨¡å‹æ­å»º

<img src="https://i.loli.net/2020/06/17/ynYRWUTDdfz9o6G.png" alt="image-20200617105329213" style="zoom:50%;" />

- å®ç°åŠŸèƒ½ï¼šé€šè¿‡é…ç½®æ–‡ä»¶æ„å»ºæ¨¡å‹ã€‚
- ä¸»è¦å…¥å£ï¼š`detectron2/detectron2/modeling/meta_arch/build.py` ä¸­çš„ `def build_model(cfg)` æ–¹æ³•ã€‚
- ç›¸å…³ä»£ç ï¼š`detectron2/detectron2/modeling` ç›®å½•ä¸‹ã€‚
- ç›¸å…³é…ç½®ï¼š`detectron2/config/defaults.py`ä¸­`_C.MODEL` å¼€å¤´çš„é…ç½®ã€‚

ã€å…¶ä»–ã€‘

* æ¨¡å‹ç›¸å…³Registryå¯¹è±¡åˆ—è¡¨
  * `ANCHOR_GENERATOR_REGISTRY`ï¼šå¦‚ä½•ç”Ÿæˆanchorsã€‚
  * `BACKBONE_REGISTRY`ï¼šä¸»å¹²ç½‘ç»œï¼ŒåŒ…æ‹¬FPNã€‚
  * `META_ARCH_REGISTRY`ï¼šåŸºæœ¬ç½‘ç»œï¼Œæ€»ä½“ç»“æ„ã€‚
  * `SEM_SEG_HEADS_REGISTRY`ï¼šåº”è¯¥æ˜¯ç”¨æ¥åšè¯­ä¹‰åˆ†éš”çš„ã€‚
  * `PROPOSAL_GENERATOR_REGISTRY`ï¼šFaster RCNNä¸­çš„Region proposal Networkï¼Œå³å¦‚ä½•ç”Ÿæˆproposalsã€‚
  * `RPN_HEAD_REGISTRY`ï¼šç¬¬ä¸€é˜¶æ®µè®­ç»ƒæ‰€éœ€çš„è¾“å…¥ã€‚
  * `ROI_BOX_HEAD_REGISTRY`ï¼šROI Headä¸­çš„bboxåˆ†æ”¯ã€‚
  * `ROI_HEADS_REGISTRY`ï¼šé€šè¿‡ç‰¹å¾å›¾å’Œç¬¬ä¸€é˜¶æ®µçš„proposalså¾—åˆ°ROIã€‚
  * `ROI_KEYPOINT_HEAD_REGISTRY`ï¼šROI Headä¸­çš„keypointåˆ†æ”¯ã€‚
  * `ROI_MASK_HEAD_REGISTRY`ï¼šROI Headä¸­çš„maskåˆ†æ”¯ã€‚

---

**åŸºæœ¬æµç¨‹**ï¼šä»¥`./modeling/meta_arch/rcnn.py/GeneralizedRCNN`ä¸ºä¾‹ï¼Œç»§æ‰¿`nn.module`ï¼ŒåŒ…æ‹¬æœ€åŸºæœ¬çš„`__init__`å’Œ`forward`å®šä¹‰ç½‘ç»œç»“æ„ï¼š

1. åœ¨`layers`å’Œ`modeling`ä¸­æ­å»ºå¥½å„ç§ç½‘ç»œç»“æ„ï¼Œå¹¶æ³¨å†Œåˆ° Registry å¯¹è±¡ä¸­ã€‚
2. æ³¨å†Œæ¨¡å‹çš„åŸºæœ¬æ¡†æ¶(meta arch)ï¼Œdetectron2ä¸­è‡ªå¸¦äº† rcnn, retinanet, semantic seg, panoptic ã€‚
3. æ ¹æ®é…ç½®æ–‡ä»¶ï¼Œåˆ†åˆ«æ„å»ºé€‰ä¸­meta archä¸­å„ä¸ªéƒ¨ä»¶ã€‚

## æ¨¡å‹è®­ç»ƒã€é¢„æµ‹ã€è¯„ä¼°

<img src="https://i.loli.net/2020/06/17/K3V47dyDkqpojmS.png" alt="image-20200617113553794" style="zoom:50%;" />

* å®ç°åŠŸèƒ½ï¼šæ¨¡å‹å­˜å–ã€ä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡ã€æŸå¤±å‡½æ•°ã€æ€§èƒ½æŒ‡æ ‡ã€TensorBoardç­‰ã€‚
* ä¸»è¦å…¥å£ï¼š`detectron2/detectron2/engine/defaults.py` ä¸­çš„ `DefaultTrainer, DefaultPredictor`ã€‚
* ç›¸å…³ä»£ç ï¼šä¸»è¦åœ¨ `detectron2/detectron2/engine` å’Œ `detectron2/detectron2/solver` ä¸­
* ç›¸å…³é…ç½®ï¼š`detectron2/config/defaults.py`ä¸­`_C.SOLVER _C.TEST` å¼€å¤´çš„é…ç½®ã€‚

---

**train** â¡ `DefaultTrainer`

**predict** â¡ `DefaultPredictor`

**evaluate** â¡ predict+æ‰‹åŠ¨eval || `DatasetEvaluator`

# å¦‚ä½•å®ç°

å¦‚æœåŸºäºå¦‚ä¸‹çš„å‡ ä¸ªéœ€æ±‚ï¼š

> 1ã€éœ€è¦å®šä¹‰è‡ªå·±çš„data_loaderï¼Œ ä»¥åŠ è½½è‡ªå·±çš„æ•°æ®é›† 
> 2ã€é’ˆå¯¹è‡ªå·±çš„è®­ç»ƒä»»åŠ¡ï¼Œæœ‰è‡ªå·±çš„è¯„ä»·æ–¹æ³•ï¼Œè€Œå¸Œæœ›è¾¹è®­è¾¹æµ‹è¯•ï¼Œæ‰€ä»¥éœ€è¦å®šä¹‰è‡ªå·±çš„EvalHookï¼Œå¹¶åœ¨Trainerä¸­è°ƒç”¨ï¼Œè¿™æ—¶å€™å°±éœ€è¦è‡ªå®šä¹‰ è‡ªå·±çš„ register_hook æ–¹æ³•
> 3ã€åœ¨æ•°æ®åŠ è½½æ—¶ï¼Œéœ€è¦å¯¹æ•°æ®è¿›è¡Œdebugï¼Œå› æ­¤éœ€è¦è‡ªå®šä¹‰è‡ªå·±çš„run_step æ–¹æ³•
> 4ã€å› ä¸ºè¿›è¡Œç®€å•è°ƒè¯•çš„æ—¶å€™ï¼Œç»å¸¸å®¹æ˜“è®­ç»ƒå‡ºnanï¼Œå› æ­¤éœ€è¦å®šä¹‰è‡ªå·±çš„_detect_anomaly æ–¹æ³•

å°±å¯ä»¥**ç»§æ‰¿DefaultTrainer**ï¼Œ å¹¶é‡å†™ç›¸å…³çš„æ–¹æ³•ï¼Œè¿›è¡Œè‡ªå®šä¹‰å³å¯ã€‚





1. åŠ è½½è‡ªå·±çš„æ•°æ®é›†

é‡å†™ `build_train_loader`

2. è‡ªå®šä¹‰Trainerç±»



# æ„Ÿæƒ³

* projecté‡Œçš„ä»£ç éå¸¸ç®€æ´

<img src="https://i.loli.net/2020/06/18/3L4ugIajDCb1WGl.png" alt="image-20200618105009630" style="zoom:50%;" />


# **Reference**

[å®˜æ–¹Tutorial](https://detectron2.readthedocs.io/tutorials/index.html)

[Colab Notebook](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5)

[APIæ–‡æ¡£](https://detectron2.readthedocs.io/modules/index.html)

[Detectron2æºç é˜…è¯»ç¬”è®°](https://www.cnblogs.com/marsggbo)ï¼ˆå¯¹åº”[çŸ¥ä¹ä¸“æ ](https://zhuanlan.zhihu.com/automl)ï¼‰

- [Detectron2æºç é˜…è¯»ç¬”è®°-(ä¸€)Config&Trainer](https://www.cnblogs.com/marsggbo/p/11677086.html)
- [Detectron2æºç é˜…è¯»ç¬”è®°-(äºŒ)Registry&build_*æ–¹æ³•](https://www.cnblogs.com/marsggbo/p/11678371.html)
- [Detectron2æºç é˜…è¯»ç¬”è®°-ï¼ˆä¸‰ï¼‰Dataset pipeline](https://www.cnblogs.com/marsggbo/p/11727556.html)

[Detectron2 æºç æµè§ˆ](https://zhuanlan.zhihu.com/p/98799433)

[çŸ¥ä¹ä¸“æ  - detectron2é¡¹ç›®æŒ‡åŒ—](https://zhuanlan.zhihu.com/c_1167741072251305984)

* [[Detectron2]04-Trainer/Hooks](https://zhuanlan.zhihu.com/p/97326458)

